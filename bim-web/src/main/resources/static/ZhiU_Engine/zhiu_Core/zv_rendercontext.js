
(function() {

	'use strict';

	var zv = ZhiUTech.Viewing,
		zvp = zv.Private;

	/**
	 * Basic manager for a list of functions called to render additional content
	 */
	function RenderCallbacks() {
		this.entries = {};

		/** 
		 * Register a function to call for rendering
		 * @param {string} name - Name of this callback
		 * @param {Function} callback - Function called when rendering
		 */
		this.add = function(name, callback) {
			this.entries[name] = {
				"callback": callback
			};
		};

		/** 
		 * Remove a previously registered callback by name
		 * @param {string} name - Name of the callback to remove
		 */
		this.remove = function(name) {
			var entry = this.entries[name];
			if(entry) {
				delete this.entries[name];
			}
		};

		/** 
		 * Run all of the registered render callbacks
		 */
		this.render = function() {
			for(var name in this.entries) {
				this.entries[name].callback();
			}
		}
	}

	zvp.RenderCallbacks = RenderCallbacks;

})();;
(function() {

	'use strict';

	var zv = ZhiUTech.Viewing,
		zvp = zv.Private;

	/** 
	 * Enumeration of important render targets generated by LMV.
	 */
	var RenderTargets = Object.freeze({
		Color: 'Color',
		Depth: 'Depth',
		ModelId: 'ModelId',
		Overlay: 'Overlay',
		Post1: 'Post1',
		PostDisplay: 'PostDisplay',
		SSAO: 'SSAO',
		Post2: 'Post2',
		Highlight: 'Highlight'
	});

	zvp.RenderTargets = RenderTargets;

})();;
(function() {

	'use strict';

	var zv = ZhiUTech.Viewing,
		zvp = zv.Private;

	function RenderContext() {

		var _renderer;
		var _depthMaterial;
		var _edgeMaterial;
		var _idMaterial;
		var _selectionMaterials = [];
		var _hasStencil = false;
		var _useStencil = false;

		//The camera and lights used for an entire progressive pass (potentially several GL frames)
		var _camera;
		var _lights;
		var _highlightLights;
		var _lastLights;
		var _fog;

		var _clearPass,
			_saoBlurPass,
			_saoPass,
			_saoMipPass,
			_saoMipFirstPass,
			_fxaaPass,
			_postProcPass,
			_blendPass,
			_copyPass,
			_highlightClearPass,
			_highlightBlendPass;

		var _pencilMap = null;
		var _graphiteMaps = [];
		var _pencilBackgroundMap = null;
		var _blendHighlight = false;

		var _saoBufferValid = false;

		var _lastX, _lastY, _lastID, _lastModelID, _lastIDValid = false;

		var _depthTarget;
		var _depthMipMap = null;
		var _colorTarget = null;
		var _overlayTarget = null;
		var _postTarget1 = null;
		var _postProcDisplayTarget = null;
		var _ssaoTarget = null;
		var _postTarget2 = null;
		var _highlightTargets = [];
		var _idTargets = [];

		var _exposureBias = 0.0;
		var _envRotation = 0.0;
		var _tonemapMethod = 0;
		var _unitScale = 1.0;

		// Occlusion test variables
		var _occlusionMaterials = [
			[],
			[]
		];
		var _occlusionTarget = null;
		var _occlusionTest = null;
		var _unitCubeVerts = null;
		var _unitCubeIndices = null;
		var _occlusionScene = null;

		var _w, _h;
		var _warnedLeak = false;

		var _readbackBuffer = new Uint8Array(4);
		var _idRes = [0, 0]; // Reused in rolloverObjectViewport

		var _white = new THREE.Color().setRGB(1, 1, 1);
		var _black = new THREE.Color().setRGB(0, 0, 0);
		var _edgeColor = new THREE.Vector4(0, 0, 0, 0.3);
		var _edgeColorHighlight = new THREE.Vector4(1, 1, 1, 1);
		var _edgeColorHighlightUnder = new THREE.Vector4(1, 1, 1, 0.5);
		var _clearColor = null;
		var _isWeakDevice = false;
		var _enableRolloverHighlight = true;

		var _renderEdges = false;
		var _isRenderingHidden = false;
		var _isRenderingOverlays = false;

		var _mrtFloat32Works = false;
		var _mrtRGBA8Works = false;
		var _depthTargetFormat = THREE.RGBFormat;
		var _depthTargetType = THREE.FloatType;
		var _depthTargetSupported = false;

		var _occlusionIds = null;
		var _occlusionIdsCopied = false;

		var _lastObjTime = 0,
			_lastHighlightId = 0,
			_lastHighlightModelId = 0,
			_easeCurve = [0.42, 0, 1, 1],
			_easeSpeed = 0.004;

		//Rendering options
		var _settings = {
			antialias: true,
			sao: false,
			useHdrTarget: false,
			haveTwoSided: false,
			useSSAA: false,
			/* Whether to use supersampled targets when antialiasing is used (default is FXAA) */
			idbuffer: true,
			occlusionid: true,
			customPresentPass: false,
			postProcShaded: false,
			envMapBg: false,
			swapBlackAndWhite: false,
			numIdTargets: 1 //must be 1 or 2; 2 is required for multi-model rollover highlight to work properly.
		};

		var _oldSettings = {};

		var zvs = ZhiUTech.Viewing.Shaders;

		//TODO: hide this once there is a way
		//to obtain the current pipeline configuration
		this.settings = _settings;

		// Create the depth target.
		function createDepthTarget(sw, sh, format, type, colorTarget) {
			var depthTarget = new THREE.WebGLRenderTarget(sw, sh, {
				minFilter: THREE.NearestFilter,
				magFilter: THREE.NearestFilter,
				format: format,
				type: type,
				stencilBuffer: _hasStencil
			});
			if(colorTarget) {
				depthTarget.shareDepthFrom = colorTarget;
			}
			depthTarget.name = "depthTarget";
			return depthTarget;
		}

		// Check whether format and type combination is supported on this device.
		function isDepthTargetTypeSupported(type) {
			try {
				var target = createDepthTarget(2, 2, type.format, type.type);
				_renderer.setRenderTarget(target);
				var gl = _renderer.context;
				var status = gl.checkFramebufferStatus(gl.FRAMEBUFFER);
				_renderer.setRenderTarget(null);
				target.dispose();
				return status === gl.FRAMEBUFFER_COMPLETE;
			} catch(e) {
				// An exception means this type isn't supported.
				return false;
			}
		}

		// Find the format and type combination for the depth targett that works for this device
		function determineDepthTargetType() {
			var types = _isWeakDevice ?
				[{
						format: THREE.RGBFormat,
						type: THREE.HalfFloatType
					},
					{
						format: THREE.RGBAFormat,
						type: THREE.HalfFloatType
					},
					{
						format: THREE.RGBFormat,
						type: THREE.FloatType
					},
					{
						format: THREE.RGBAFormat,
						type: THREE.FloatType
					},
				] : [{
						format: THREE.RGBFormat,
						type: THREE.FloatType
					},
					{
						format: THREE.RGBAFormat,
						type: THREE.FloatType
					},
					{
						format: THREE.RGBFormat,
						type: THREE.HalfFloatType
					},
					{
						format: THREE.RGBAFormat,
						type: THREE.HalfFloatType
					},
				];

			var type = types.find(isDepthTargetTypeSupported);

			if(type) {
				_depthTargetSupported = true;
				_depthTargetFormat = type.format;
				_depthTargetType = type.type;
			} else {
				_depthTargetSupported = false;
				zvp.logger.warn("Depth target is unsupported for this device.");
			}
		}

		this.init = function(glrenderer, width, height) {

			createRenderPasses();

			if(!glrenderer) {
				zvp.logger.error("You need a gl context to make a renderer. Things will go downhill from here.", zv.errorCodeString(zv.ErrorCodes.BROWSER_WEBGL_NOT_SUPPORTED));
				return;
			}

			_isWeakDevice = zv.isMobileDevice();

			_settings.idbuffer = !_isWeakDevice;

			_w = width;
			_h = height;

			_renderer = glrenderer;
			_hasStencil = !!_renderer.context.getContextAttributes().stencil;

			determineDepthTargetType();

			//delayed until first begin frame
			//this.initPostPipeline(_settings.sao, _settings.antialias);

		};

		// Creates material for normal-depth shader - including alternative variants
		// for instancing and with/without cutplanes.
		function createDepthMaterial() {

			// create main/default override material first
			var depthShader = zvs.NormalsShader;
			_depthMaterial = zvs.createShaderMaterial(depthShader);
			_depthMaterial.blending = THREE.NoBlending;
			_depthMaterial.packedNormals = true;
			// normally the color target will write to the z-buffer, so depth does not need to do so.
			_depthMaterial.depthWrite = false;

			// Flags to define alternative depth material variants.
			var DepthMaterialFlags = {
				NoCutPlanes: 0x1, // Without cutplanes to render section caps
				Instancing: 0x2, // Using instancing
				Count: 0x4
			};

			// create special-case material variants
			var variants = [];
			variants[0] = null; // index 0 = null (=use default depthMaterial)
			for(var i = 1; i < DepthMaterialFlags.Count; i++) {
				var variant = _depthMaterial.clone();

				// cutplanes: with/without
				if(i & DepthMaterialFlags.NoCutPlanes) {
					variant.cutPlanes = null;
					variant.blending = THREE.NoBlending;
					variant.packedNormals = true;
					variant.doNotCut = true; // make sure that cutplanes keep null (see MaterialManager.addMaterialNonHDR)
				}

				// instancing yes/no
				if(i & DepthMaterialFlags.Instancing) {
					variant.useInstancing = true;
				}

				variants[i] = variant;
			}

			_depthMaterial.variants = variants;

			// Define a custom override function: It decides for a shape
			// which depthMaterial variant will be used by WebGLRenderer.
			_depthMaterial.getCustomOverrideMaterial = function(shapeMaterial) {

				// If the original shape material has no cutplanes, use the alternative
				// _noCutplanesMaterial for normal/depth.
				var noCutPlanes = (!shapeMaterial || !shapeMaterial.cutplanes || shapeMaterial.cutplanes.length == 0);

				// If the original material applies the instance transform, depthMaterial must do this as well.
				var instanced = shapeMaterial.useInstancing;

				// return the appropriate material variant
				var index =
					(noCutPlanes ? DepthMaterialFlags.NoCutPlanes : 0) |
					(instanced ? DepthMaterialFlags.Instancing : 0);
				return this.variants[index];
			};
		}

		function createEdgeMaterial() {
			// create main/default override material first
			var edgeShader = zvs.EdgeShader;
			_edgeMaterial = zvs.createShaderMaterial(edgeShader);
			_edgeMaterial.depthWrite = true;
			_edgeMaterial.depthTest = true;
			_edgeMaterial.isEdgeMaterial = true;
			_edgeMaterial.transparent = true;
			_edgeMaterial.blending = THREE.NormalBlending;

			// Flags to define alternative edge material variants.
			var EdgeMaterialFlags = {
				Instancing: 0x1, // Using instancing
				Count: 2
			};

			// create special-case material variants
			var variants = [];
			variants[0] = null; // index 0 = null (=use default edgeMaterial)
			for(var i = 1; i < EdgeMaterialFlags.Count; i++) {
				var variant = _edgeMaterial.clone();

				//Have to clone this manually, otherwise it's shared between the clones
				variant.defines = zv.ObjectAssign({}, _edgeMaterial.defines);

				variant.isEdgeMaterial = true;

				// instancing yes/no
				if(i & EdgeMaterialFlags.Instancing) {
					variant.useInstancing = true;
				}

				variants[i] = variant;
			}

			_edgeMaterial.variants = variants;

			// Define a custom override function: It decides for a shape
			// which depthMaterial variant will be used by WebGLRenderer.
			_edgeMaterial.getCustomOverrideMaterial = function(shapeMaterial) {

				// If the original material applies the instance transform, depthMaterial must do this as well.
				var instanced = shapeMaterial.useInstancing;

				// return the appropriate material variant
				var index = (instanced ? EdgeMaterialFlags.Instancing : 0);

				var mat = this.variants[index] || _edgeMaterial;

				//Unlike depth test settings, we need to change uniforms on the material variant
				//for them to take effect
				if(_isRenderingOverlays) {
					if(_isRenderingHidden) {
						mat.uniforms.color.value = _edgeColorHighlightUnder;
					} else {
						mat.uniforms.color.value = _edgeColorHighlight;
					}
				} else {
					mat.uniforms.color.value = _edgeColor;
				}
				mat.uniforms.color.needsUpdate = true;

				return mat;
			};
		}

		this.setDepthMaterialOffset = function(on, factor, units) {
			var cb = function(mat) {
				mat.polygonOffset = on;
				mat.polygonOffsetFactor = factor;
				mat.polygonOffsetUnits = units;
				if(mat.extraDepthOffset) {
					mat.polygonOffsetFactor += mat.extraDepthOffset;
				}
				mat.needsUpdate = true;
			};
			forEachDepthMaterial(cb);
		};

		// Calls the cb for all depth material variants (including default)
		function forEachDepthMaterial(cb) {
			cb(_depthMaterial);
			for(var i = 1; i < _depthMaterial.variants.length; i++) {
				cb(_depthMaterial.variants[i]);
			}
		}

		function createRenderPasses() {

			function setNoDepthNoBlend(pass) {
				pass.material.blending = THREE.NoBlending;
				pass.material.depthWrite = false;
				pass.material.depthTest = false;
			}

			createDepthMaterial();
			createEdgeMaterial();

			_saoPass = new zvs.LmvShaderPass(zvs.SAOShader);
			setNoDepthNoBlend(_saoPass);

			_saoBlurPass = new zvs.LmvShaderPass(zvs.SAOBlurShader);
			setNoDepthNoBlend(_saoBlurPass);

			_saoMipFirstPass = new zvs.LmvShaderPass(zvs.SAOMinifyFirstShader);
			setNoDepthNoBlend(_saoMipFirstPass);

			_saoMipPass = new zvs.LmvShaderPass(zvs.SAOMinifyShader);
			setNoDepthNoBlend(_saoMipPass);

			_fxaaPass = new zvs.LmvShaderPass(zvs.FXAAShader);
			setNoDepthNoBlend(_fxaaPass);

			_postProcPass = new zvs.LmvShaderPass(zvs.CelShader);
			setNoDepthNoBlend(_postProcPass);

			_blendPass = new zvs.LmvShaderPass(zvs.BlendShader);
			setNoDepthNoBlend(_blendPass);

			_clearPass = new zvs.LmvShaderPass(zvs.BackgroundShader);
			setNoDepthNoBlend(_clearPass);

			_copyPass = new zvs.LmvShaderPass(zvs.CopyShader);
			setNoDepthNoBlend(_copyPass);

			_highlightClearPass = new zvs.LmvShaderPass(zvs.ClearShader);
			setNoDepthNoBlend(_highlightClearPass);

			_highlightBlendPass = new zvs.LmvShaderPass(zvs.HighlightShader);
			// Use custom blend under for this pass. This blends the output of the shader
			// under the contents of the overlay target.
			_highlightBlendPass.material.depthWrite = false;
			_highlightBlendPass.material.depthTest = false;
			_highlightBlendPass.material.blending = THREE.CustomBlending;
			_highlightBlendPass.material.blendDst = THREE.DstAlphaFactor;
			_highlightBlendPass.material.blendDstAlpha = THREE.OneFactor;
			_highlightBlendPass.material.blendSrc = THREE.OneMinusDstAlphaFactor;
			_highlightBlendPass.material.blendSrcAlpha = THREE.OneMinusDstAlphaFactor;
			_highlightBlendPass.material.blendEquation = THREE.AddEquation;
			_highlightBlendPass.material.uniforms.edgeColor.value = _edgeColorHighlight.clone();
			_highlightBlendPass.material.transparent = true;
		}

		/**
		 * Returns true if render target with given name is used by at least one rendering component or effect.
		 * @param {String} targetName - Render target name (see RenderTargets for complete list)
		 */
		function isRenderTargetUsed(targetName) {
			switch(targetName) {
				case zvp.RenderTargets.Color:
					return true;
				case zvp.RenderTargets.Depth:
					return _depthTargetSupported && (_settings.sao || _settings.postProcShaded);
				case zvp.RenderTargets.ModelId:
					return(_settings.idbuffer || _settings.occlusionid);
				case zvp.RenderTargets.Overlay:
					return true;
				case zvp.RenderTargets.SSAO:
					return _settings.sao;
				case zvp.RenderTargets.Post1:
					return(_settings.antialias || _settings.sao || _settings.customPresentPass || _settings.postProcShaded);
				case zvp.RenderTargets.Post2:
					return(_settings.postProcShaded || _settings.customPresentPass);
				case zvp.RenderTargets.PostDisplay:
					return(_settings.antialias && _settings.postProcShaded); // we assume blending is available.
				case zvp.RenderTargets.Highlight:
					return true;
			}
		}

		function createRenderTarget(targetName, ww, hh) {
			var target = null;
			switch(targetName) {
				case zvp.RenderTargets.ModelId:
					{
						target = new THREE.WebGLRenderTarget(ww, hh, {
							minFilter: THREE.NearestFilter,
							magFilter: THREE.NearestFilter,
							format: THREE.RGBAFormat,
							type: THREE.UnsignedByteType,
							stencilBuffer: _hasStencil
						});
						target.generateMipmaps = false;
						target.shareDepthFrom = _colorTarget;

						//Set this flag to avoid checking frame buffer status every time we read
						//a pixel from the ID buffer. We know the ID target is compatible with readPixels.
						target.canReadPixels = true;
					}
					break;
			}
			return target;
		}

		function cubicBezier(p, t) {
			//var cx = 3.0 * p[0];
			//var bx = 3.0 * (p[2] - p[0]) - cx;
			//var ax = 1.0 - cx -bx;
			var cy = 3.0 * p[1];
			var by = 3.0 * (p[3] - p[1]) - cy;
			var ay = 1.0 - cy - by;

			//return ((ax * t + bx) * t + cx) * t;
			return((ay * t + by) * t + cy) * t;
		}

		// Fades the overlay update in over time.
		// For rollover highlighting, which increases in effect as you wait.
		this.overlayUpdate = function() {

			if(_lastHighlightId === 0 || _lastHighlightId === -1)
				return false;

			var old = _blendPass.uniforms.highlightIntensity.value;

			// Multiply number of milliseconds that has elapsed by the
			// speed, 1/milliseconds, the time the transition should take.
			// So if _easeSpeed is, say, 1/1000, the transition takes a second;
			// 2/1000 is half a second, etc.
			var t = ((performance.now() - _lastObjTime) * _easeSpeed);
			t = Math.min(t, 1.0);

			// not a linear transition; use a cubic Bezier curve to ease in and out
			var current = cubicBezier(_easeCurve, t);

			// if intensity value has changed, update the shader's uniform
			if(old != current) {
				_blendPass.uniforms.highlightIntensity.value = current;
				return true;
			}

			return false;
		};

		this.clearHighlight = function() {
			_blendHighlight = false;
			if(isRenderTargetUsed(zvp.RenderTargets.Highlight)) {
				_renderer.setClearColor(_black, 0.0);
				for(var i = 0; i < _highlightTargets.length; ++i) {
					_renderer.clearTarget(_highlightTargets[i], true, false, false);
				}
			}
		};

		this.setHighlightLights = function(customLights) {
			_highlightLights = customLights;
		};

		// clear the color target and other targets, as needed
		this.beginScene = function(prototypeScene, camera, customLights, needClear) {
			_camera = camera;
			_fog = prototypeScene.fog;
			_lights = customLights;
			_saoBufferValid = false;
			_lastIDValid = false;

			if(!_colorTarget && _w) {
				this.initPostPipeline(_settings.sao, _settings.antialias);
			} else if(!_colorTarget && !_w) {
				if(!_warnedLeak) {
					zvp.logger.error("Rendering to a canvas that was resized to zero. If you see this message you may be accidentally leaking a viewer instance.", zv.errorCodeString(zv.ErrorCodes.VIEWER_INTERNAL_ERROR));
					_warnedLeak = true;
				}
				return;
			}

			//We need to render once with the "prototype" scene which
			//only contains the cameras and lights, so that their positions
			//and transforms get updated to the latest camera. Hence the
			//call to render instead of just clear.

			//Clear the color target
			if(needClear) {

				if(_clearColor && !_settings.envMapBg) {
					if(_settings.swapBlackAndWhite) {
						var white = new THREE.Color(1, 1, 1);
						var black = new THREE.Color(0, 0, 0);
						if(_clearColor.equals(white)) {
							_renderer.setClearColor(black, 1.0);
						} else if(_clearColor.equals(black)) {
							_renderer.setClearColor(white, 1.0);
						} else {
							_renderer.setClearColor(_clearColor, 1.0);
						}
					} else {
						_renderer.setClearColor(_clearColor, 1.0);
					}
					_renderer.clearTarget(_colorTarget, true, true, _hasStencil); //clear color and depth buffer
				} else {

					_clearPass.uniforms['uCamDir'].value = _camera.worldUpTransform ? _camera.getWorldDirection().clone().applyMatrix4(_camera.worldUpTransform) : _camera.getWorldDirection();
					_clearPass.uniforms['uCamUp'].value = _camera.worldUpTransform ? _camera.up.clone().applyMatrix4(_camera.worldUpTransform) : _camera.up;
					_clearPass.uniforms['uResolution'].value.set(_w, _h);
					_clearPass.uniforms['uHalfFovTan'].value = Math.tan(THREE.Math.degToRad(_camera.fov * 0.5));

					_renderer.clearTarget(_colorTarget, false, true, _hasStencil); //clear depth buffer
					_clearPass.render(_renderer, _colorTarget, null); //clear the color buffer
				}

				//Clear the id buffer(s)
				for(var i = 0; i < _idTargets.length; i++) {
					_renderer.setClearColor(_white, 1.0);
					_renderer.clearTarget(_idTargets[i], true, false, false);
				}
				this.clearHighlight();
				_occlusionIdsCopied = false;
			}

			//Clear the G-buffer target if needed and update the SSAO uniforms.
			if(isRenderTargetUsed(zvp.RenderTargets.Depth)) {

				if(needClear) {
					_renderer.setClearColor(_black, 0.0);
					//Skip clearing the depth buffer as it's shared with the color target
					_renderer.clearTarget(_depthTarget, true, false, false);
				}

				var near = camera.near;
				var far = camera.far;

				_saoPass.uniforms['cameraNear'].value = near;
				_saoPass.uniforms['cameraFar'].value = far;
				_postProcPass.uniforms['cameraNear'].value = near;
				_postProcPass.uniforms['cameraFar'].value = far;

				_saoMipFirstPass.uniforms['cameraNear'].value = near;
				_saoMipFirstPass.uniforms['cameraInvNearFar'].value = 1.0 / (near - far);

				var P = camera.projectionMatrix.elements;

				//Scaling factor needed to increase contrast of our SSAO.
				if(camera.isPerspective) {
					/*  vec4(-2.0f / (width*P[0][0]),
					 -2.0f / (height*P[1][1]),
					 ( 1.0f - P[0][2]) / P[0][0],
					 ( 1.0f + P[1][2]) / P[1][1])*/
					_saoPass.uniforms['projInfo'].value.set(-2.0 / (_colorTarget.width * P[0]), -2.0 / (_colorTarget.height * P[5]),
						(1.0 - P[8]) / P[0],
						(1.0 + P[9]) / P[5]); //TODO: Not certain if we need + or - here for OpenGL off-center matrix (original is DX-style)
					//would have to verify if some day we have off-center projections.
				} else {
					_saoPass.uniforms['projInfo'].value.set(-2.0 / (_colorTarget.width * P[0]), -2.0 / (_colorTarget.height * P[5]),
						(1.0 - P[12]) / P[0],
						(1.0 - P[13]) / P[5]);
				}
				_postProcPass.uniforms['projInfo'].value.copy(_saoPass.uniforms['projInfo'].value);
				var isOrtho = (camera.isPerspective ? 0.0 : 1.0);
				_saoPass.uniforms['isOrtho'].value = isOrtho;
				_postProcPass.uniforms['isOrtho'].value = isOrtho;

				var hack_scale = 0.25;
				_saoPass.uniforms['projScale'].value = hack_scale * 0.5 * (_colorTarget.height * P[5]);

				// an approximation of the size of the world; relies on the camera's near and far being reasonable.
				// This is not a great solution, as orbiting changes this number. Better would be the length of
				// the diagonal of the whole world, or perhaps the *shortest* dimension (so that cities get SAO).
				// This method is variable on the camera's view. Better is to do this in Viewer3dImpl.addModel,
				// which is where we do this now.
				//this.setAOOptions( 0.05*(camera.far-camera.near) );
			}

			if(!_settings.sao) {
				// Ensure that any previous SSAO computation post-process target is not blended in.
				// This looks redundant with computeSSAO()'s code setting this blend off. However, it's
				// possible for computeSSAO() to not be executed if (a) smooth navigation and AO are both on
				// and (b) the scene is moving. In that case, smooth navigation turns off AO entirely in
				// Viewer3DImpl.js and computSSAO() is never called at all.
				_blendPass.uniforms['useAO'].value = 0;
			}

			// Render the prototype/pre-model scene, which may also contain some user added custom geometry.
			// The key bit here is the "updateLights" true flag, which updates the lights for the scene; this is the
			// only place this flag is passed in as true.
			this.renderScenePart(prototypeScene, true, true, false, 0, true);
		};

		this.copyOcclusionIds = function() {
			if(!_settings.occlusionid || !_idTargets[0] || !_occlusionIds)
				return null;
			if(!_occlusionIdsCopied)
				_renderer.readRenderTargetPixels(_idTargets[0], 0, 0, _idTargets[0].width, _idTargets[0].height, _occlusionIds);
			return _occlusionIds;
		};

		// Called incrementally by the scene traversal, potentially
		// across several frames.
		this.renderScenePart = function(scene, want_colorTarget, want_saoTarget, want_idTarget, want_highlightTarget, updateLights) {

			// Need to handle occlusion ids. Get the id values when we render the first transparent scene.
			if(want_idTarget && _settings.occlusionid && _idTargets[0] &&
				_occlusionIds && scene instanceof zvp.RenderBatch) {
				_occlusionIdsCopied = false;
			}

			//console.time("renderScenePart");
			_saoBufferValid = false;
			_lastIDValid = false;
			//update scene with stored _fog shared from prototypeScene fog.
			scene.fog = _fog;
			if(_useStencil) {
				var ref = want_highlightTarget ? 1 : 0;
				_renderer.state.buffers.stencil.setFunc(_renderer.context.ALWAYS, ref, 1);
			}

			//Three possibilities here -- MRT fully supported (Mac OS or native GL backends on Windows).
			//MRT supported only for targets that have exactly equal number of bitplanes and bpp (ANGLE on Windows)
			//MRT not supported at all. (Not sure --> some mobile platforms?).

			var oldMat;
			var lights;
			if(want_colorTarget) {
				lights = undefined;
				if(updateLights || _lights !== _lastLights) {
					lights = _lights;
					_lastLights = lights;
				}

				if(_mrtFloat32Works && _mrtRGBA8Works) {
					//You lucky dog! Fast code path for you.

					//In case of MRT, we ignore the which target flags, because
					//we assume the shaders are set up to write to the multiple targets anyway.
					//NOP: except idTarget, since hidden pass doesn't want that
					if(isRenderTargetUsed(zvp.RenderTargets.ModelId) && want_idTarget && isRenderTargetUsed(zvp.RenderTargets.Depth)) {
						_renderer.render(scene, _camera, [_colorTarget, _depthTarget].concat(_idTargets), false, lights);
					} else if(isRenderTargetUsed(zvp.RenderTargets.Depth)) {
						_renderer.render(scene, _camera, [_colorTarget, _depthTarget], false, lights);
					} else if(isRenderTargetUsed(zvp.RenderTargets.ModelId) && want_idTarget) {
						_renderer.render(scene, _camera, [_colorTarget].concat(_idTargets));
					} else /*if (_settings.antialias)*/ {
						_renderer.render(scene, _camera, _colorTarget, false, lights);
					}
					//else {
					//    _renderer.render(scene, _camera, null);
					//}

				} else if(_mrtRGBA8Works) {
					//It's something...

					if(isRenderTargetUsed(zvp.RenderTargets.ModelId) && want_idTarget) {
						_renderer.render(scene, _camera, [_colorTarget].concat(_idTargets), false, lights);
					} else /*if (_settings.antialias)*/ {
						_renderer.render(scene, _camera, _colorTarget, false, lights);
					}

					//Float target has to be rendered separately in case we can't
					//bind MRT with different bpp targets.
					// We do not render transparent objects to the depth target, which is currently used only for ambient shadows.
					// This is the same as sortObjects === true.
					// If we someday do render to depth target for other things, such as a good near, we will need to perhaps do
					// a separate pass to get the near, rendering all objects. (We'll have a good "far", since transparent objects will be off.)
					if(isRenderTargetUsed(zvp.RenderTargets.Depth) && want_saoTarget && !scene.sortObjects) {
						//Render the depth pass
						oldMat = scene.overrideMaterial;

						scene.overrideMaterial = _depthMaterial;

						// If color or ID target was written, then the z-buffer is established and we don't need to write to it any more.
						// NOTE: until cutouts are dealt with properly by the depth material, there will still be mismatches.
						// If the color buffer already wrote to the z-buffer, don't write to it. This saves memory accesses
						// and more importantly means that the depth material doesn't need to take account of any cutout materials,
						// as now only the color pass will write to the hardware z-buffer, and that pass does it right.
						if(_depthMaterial.depthWrite !== depthWriteToZbuffer) {
							// set depth write state as needed
							_depthMaterial.depthWrite = depthWriteToZbuffer;
							_depthMaterial.needsUpdate = true;
						}

						_renderer.render(scene, _camera, _depthTarget, false);

						scene.overrideMaterial = oldMat;
					}

				} else {

					//Poor sod. No MRT at all. Three passes.

					//Render the color target first -- actually this is slower
					//because the color shader is likely a lot slower than the
					//depth+normal shader, but if we render depth first, then
					//we lose stuff behind transparent objects (potentially).
					//So we cannot do this until the progressive render is split
					//into non-transparent and transparent worlds.

					// see if depth target needs to write to z-buffer, not just read it
					var depthWriteToZbuffer = false; // assume the color buffer will write to z already: LMV-2375
					if(want_colorTarget) {
						_renderer.render(scene, _camera, _colorTarget, false, lights);
					} else {
						// This branch will never be hit with the current code - the color target
						// is always generated. But, future-proofing.
						depthWriteToZbuffer = true;
					}

					//TODO: In 3D we really don't want to get into
					//this situation -- we don't have a reasonable ID material that
					//will work for e.g. cutout maps. We have to run basically a full
					//shader, or at least one that support opacity and alpha map checks.
					if(isRenderTargetUsed(zvp.RenderTargets.ModelId) && want_idTarget) {

						// TODO: the ID buffer should also probably not write to the z-buffer if the
						// color target already has. The _idMaterial should be adjusted. The bug that may
						// occur without this fixed is that objects with cutouts may instead fully cover
						// areas they should not. See LMV-2375.
						// Also, if the color buffer is *not* rendered, then the id buffer should use a special
						// material to represent cutout materials, so cutouts are treated properly and block only
						// the areas they truly cover.
						if(_idMaterial) {
							oldMat = scene.overrideMaterial;
							scene.overrideMaterial = _idMaterial;
							//TODO: This code path does not work in case multiple id targets are attached
							//We need a second ID material that renders modelId instead of dbId.
							_renderer.render(scene, _camera, _idTargets[0], false);
							scene.overrideMaterial = oldMat;
						} else {
							_renderer.setProgramPrefix(1, "#define ID_COLOR", "#define ID_COLOR");
							//TODO: This code path does not work in case multiple id targets are attached
							//We need a second ID material that renders modelId instead of dbId.
							_renderer.render(scene, _camera, _idTargets[0], false);
							_renderer.setProgramPrefix(0, "", "");
						}
						depthWriteToZbuffer = false;
					}

					// We do not render transparent objects to the depth target, which is currently used only for ambient shadows.
					// This is the same as sortObjects === true.
					// If we someday do render to depth target for other things, such as a good near, we will need to perhaps do
					// a separate pass to get the near, rendering all objects. (We'll have a good "far", since transparent objects will be off.)
					if(isRenderTargetUsed(zvp.RenderTargets.Depth) && want_saoTarget && !scene.sortObjects) {
						//Render the depth pass
						oldMat = scene.overrideMaterial;

						// If color or ID target was written, then the z-buffer is established and we don't need to write to it any more.
						// NOTE: until cutouts are dealt with properly by the depth material, there will still be mismatches.
						// If the color buffer already wrote to the z-buffer, don't write to it. This saves memory accesses
						// and more importantly means that the depth material doesn't need to take account of any cutout materials,
						// as now only the color pass will write to the hardware z-buffer, and that pass does it right.
						if(_depthMaterial.depthWrite !== depthWriteToZbuffer) {
							// set depth write state as needed
							_depthMaterial.depthWrite = depthWriteToZbuffer;
							_depthMaterial.needsUpdate = true;
						}

						scene.overrideMaterial = _depthMaterial;

						_renderer.render(scene, _camera, _depthTarget, false);

						scene.overrideMaterial = oldMat;
					}

				}

				//Do a second pass to render edges, if needed.
				//TODO: Investigate if it will be faster to integrate
				//this draw call into the main color target render call, similar
				//to how decal materials are done inside the renderer.
				if(want_colorTarget && _renderEdges) {
					oldMat = scene.overrideMaterial;
					scene.overrideMaterial = _edgeMaterial;
					_renderer.context.depthFunc(_renderer.context.LESS); //hope to avoid some line-on-line overdraw this way
					_renderer.render(scene, _camera, [_colorTarget], false);
					_renderer.context.depthFunc(_renderer.context.LEQUAL);
					scene.overrideMaterial = oldMat;
				}
			}

			if(want_highlightTarget) {
				lights = undefined;
				if(_highlightLights !== _lastLights) {
					lights = _highlightLights;
					_lastLights = lights;
				}

				oldMat = scene.overrideMaterial;
				_isRenderingOverlays = true;
				_edgeMaterial.depthWrite = false;
				for(var i = 0; i < _selectionMaterials.length; ++i) {
					// The highlight pass is completely separate and just draws to the highlightTarget
					var selectionMaterial = _selectionMaterials[i];
					if(want_highlightTarget & (1 << i)) {
						_blendHighlight = true;
						_isRenderingHidden = selectionMaterial.renderHidden;
						_edgeMaterial.depthTest = !_isRenderingHidden;
						scene.overrideMaterial = selectionMaterial.material;
						_renderer.render(scene, _camera, _highlightTargets[selectionMaterial.target], false, lights);
						lights = undefined;
					}
				}
				_isRenderingOverlays = false;
				_isRenderingHidden = false;
				_edgeMaterial.depthWrite = true;
				_edgeMaterial.depthTest = true;
				scene.overrideMaterial = oldMat;
			}

			//console.timeEnd("renderScenePart");
		};

		function createOcclusionTarget() {
			_occlusionTarget = new THREE.WebGLRenderTarget(
				_settings.deviceWidth, _settings.deviceHeight, {
					minFilter: THREE.NearestFilter,
					magFilter: THREE.NearestFilter,
					format: THREE.RGBAFormat,
					stencilBuffer: _hasStencil
				});
			_occlusionTarget.generateMipmaps = false;
			_occlusionTarget.shareDepthFrom = _colorTarget;
		}

		function addVerts(bboxVerts, toVerts, boxes, from) {
			// Eight corners of the box
			bboxVerts[toVerts++] = boxes[from];
			bboxVerts[toVerts++] = boxes[from + 1];
			bboxVerts[toVerts++] = boxes[from + 2];

			bboxVerts[toVerts++] = boxes[from + 3];
			bboxVerts[toVerts++] = boxes[from + 1];
			bboxVerts[toVerts++] = boxes[from + 2];

			bboxVerts[toVerts++] = boxes[from];
			bboxVerts[toVerts++] = boxes[from + 4];
			bboxVerts[toVerts++] = boxes[from + 2];

			bboxVerts[toVerts++] = boxes[from + 3];
			bboxVerts[toVerts++] = boxes[from + 4];
			bboxVerts[toVerts++] = boxes[from + 2];

			bboxVerts[toVerts++] = boxes[from];
			bboxVerts[toVerts++] = boxes[from + 1];
			bboxVerts[toVerts++] = boxes[from + 5];

			bboxVerts[toVerts++] = boxes[from + 3];
			bboxVerts[toVerts++] = boxes[from + 1];
			bboxVerts[toVerts++] = boxes[from + 5];

			bboxVerts[toVerts++] = boxes[from];
			bboxVerts[toVerts++] = boxes[from + 4];
			bboxVerts[toVerts++] = boxes[from + 5];

			bboxVerts[toVerts++] = boxes[from + 3];
			bboxVerts[toVerts++] = boxes[from + 4];
			bboxVerts[toVerts++] = boxes[from + 5];
			return toVerts;
		}

		function addIndices(bboxIndices, toIndices, indexBase) {
			// -y
			bboxIndices[toIndices++] = indexBase;
			bboxIndices[toIndices++] = indexBase + 1;
			bboxIndices[toIndices++] = indexBase + 5;
			bboxIndices[toIndices++] = indexBase;
			bboxIndices[toIndices++] = indexBase + 5;
			bboxIndices[toIndices++] = indexBase + 4;

			// -z
			bboxIndices[toIndices++] = indexBase;
			bboxIndices[toIndices++] = indexBase + 2;
			bboxIndices[toIndices++] = indexBase + 3;
			bboxIndices[toIndices++] = indexBase;
			bboxIndices[toIndices++] = indexBase + 3;
			bboxIndices[toIndices++] = indexBase + 1;

			// -x
			bboxIndices[toIndices++] = indexBase;
			bboxIndices[toIndices++] = indexBase + 4;
			bboxIndices[toIndices++] = indexBase + 6;
			bboxIndices[toIndices++] = indexBase;
			bboxIndices[toIndices++] = indexBase + 6;
			bboxIndices[toIndices++] = indexBase + 2;

			// +z
			bboxIndices[toIndices++] = indexBase + 7;
			bboxIndices[toIndices++] = indexBase + 6;
			bboxIndices[toIndices++] = indexBase + 4;
			bboxIndices[toIndices++] = indexBase + 7;
			bboxIndices[toIndices++] = indexBase + 4;
			bboxIndices[toIndices++] = indexBase + 5;

			// +x
			bboxIndices[toIndices++] = indexBase + 7;
			bboxIndices[toIndices++] = indexBase + 5;
			bboxIndices[toIndices++] = indexBase + 1;
			bboxIndices[toIndices++] = indexBase + 7;
			bboxIndices[toIndices++] = indexBase + 1;
			bboxIndices[toIndices++] = indexBase + 3;

			// +y
			bboxIndices[toIndices++] = indexBase + 7;
			bboxIndices[toIndices++] = indexBase + 3;
			bboxIndices[toIndices++] = indexBase + 2;
			bboxIndices[toIndices++] = indexBase + 7;
			bboxIndices[toIndices++] = indexBase + 2;
			bboxIndices[toIndices++] = indexBase + 6;

			return toIndices;
		}

		function createBBoxGeometry(boxes, fragIds, start, length) {
			var bboxVerts = new Float32Array(length * 24);
			var bboxIndices = new Uint16Array(length * 36);
			var toVerts = 0,
				toIndices = 0,
				indexBase = 0;
			length += start;
			for(; start < length; ++start, indexBase += 8) {
				// Copy indices and vertices for the box
				toIndices = addIndices(bboxIndices, toIndices, indexBase);
				toVerts = addVerts(bboxVerts, toVerts, boxes, fragIds[start] * 6);
			}

			var geometry = new THREE.BufferGeometry();
			geometry.addAttribute('position', new THREE.BufferAttribute(bboxVerts, 3));
			geometry.addAttribute('index', new THREE.BufferAttribute(bboxIndices, 1));
			geometry.streamingDraw = true;
			geometry.streamingIndex = true;
			return geometry;
		}

		function createInstancedBBoxGeometry(boxes, fragIds, start, length) {
			// Don't interleave the min and max vertices.
			var minVerts = new Float32Array(length * 3);
			var scaleVerts = new Float32Array(length * 3);
			var toVerts = 0;
			var end = length + start;
			for(; start < end; ++start) {
				var from = fragIds[start] * 6;
				scaleVerts[toVerts] = boxes[from + 3] - boxes[from];
				minVerts[toVerts++] = boxes[from++];
				scaleVerts[toVerts] = boxes[from + 3] - boxes[from];
				minVerts[toVerts++] = boxes[from++];
				scaleVerts[toVerts] = boxes[from + 3] - boxes[from];
				minVerts[toVerts++] = boxes[from++];
			}

			var geometry = new THREE.BufferGeometry();
			geometry.addAttribute('position', new THREE.BufferAttribute(_unitCubeVerts, 3));
			geometry.addAttribute('index', new THREE.BufferAttribute(_unitCubeIndices, 1));
			var minAttr = new THREE.BufferAttribute(minVerts, 3);
			minAttr.divisor = 1;
			var scaleAttr = new THREE.BufferAttribute(scaleVerts, 3);
			scaleAttr.divisor = 1;
			geometry.addAttribute('instOffset', minAttr);
			geometry.addAttribute('instScaling', scaleAttr);
			geometry.numInstances = length;
			geometry.streamingDraw = true;
			geometry.streamingIndex = true;
			return geometry;
		}

		function createUnitCube() {
			// Create unit cube vertex and index buffers
			_unitCubeVerts = new Float32Array(24);
			_unitCubeIndices = new Uint16Array(36);
			addIndices(_unitCubeIndices, 0, 0);
			addVerts(_unitCubeVerts, 0, [0, 0, 0, 1, 1, 1], 0);
		}

		// Create the occlusion materials for testing. The materials can test one pack file
		// in each color component, R, G, B, or A. The colors are setup so we can blend
		// each component separately using D = D * S. The target is initialized to opaque
		// white and a 0 in a component means a pixel was drawn. Doing it this way
		// makes it easier to see the results if we need to look at the bitmap.
		// The colors and alphas are ordered to match the byte ordering in the pixel.
		var colors = [
			[0, 1, 1],
			[1, 0, 1],
			[1, 1, 0],
			[1, 1, 1]
		];
		var alphas = [1, 1, 1, 0];

		function createOcclusionMaterials(length, instanced) {
			var useInstancing = !!instanced;
			for(var i = _occlusionMaterials[instanced].length; i < length; ++i) {
				var occlusionMaterial = zvs.createShaderMaterial(WGS.OcclusionShader);
				occlusionMaterial.useInstancing = useInstancing;
				occlusionMaterial.depthWrite = false;
				occlusionMaterial.uniforms.color.value.set(colors[i][0], colors[i][1], colors[i][2]);
				occlusionMaterial.uniforms.opacity.value = alphas[i];
				occlusionMaterial.defaultAttributeValues.instRotate = [1, 0, 0, 0];
				occlusionMaterial.blending = THREE.CustomBlending;
				occlusionMaterial.blendDst = THREE.SrcColorFactor;
				occlusionMaterial.blendSrc = THREE.ZeroFactor;
				occlusionMaterial.blendEquation = THREE.AddEquation;
				occlusionMaterial.transparent = true;
				_occlusionMaterials[instanced][i] = occlusionMaterial;
			}
		}

		// For debugging, show occlusion target for some pack files
		var showOcclusion = {};
		// Return whether the fragment ids are occluded
		this.occlusionTest = function(boxes, threshold, fragIds, useInstancing, packIds) {
			if(!fragIds || fragIds.length <= 0 || fragIds.length > 4)
				return Promise.reject({
					error: "fragIds invalid. Must be a nonempty array of fragment id arrays with length <= 4"
				});

			var counts = [0, 0, 0, 0];
			var visibleCount = 0;
			useInstancing = (useInstancing && _renderer.supportsInstancedArrays()) ? 1 : 0;
			if(!_occlusionMaterials[useInstancing] || _occlusionMaterials[useInstancing].length < fragIds.length)
				createOcclusionMaterials(fragIds.length, useInstancing);

			if(useInstancing && !_unitCubeVerts)
				createUnitCube();

			// Create a scene for the boxes
			if(!_occlusionScene)
				_occlusionScene = new THREE.Scene();
			_occlusionScene.frustumCulled = false;

			// Be careful and don't create buffers to large for short indices
			// 8 vertices per fragment box out of 64K vertices max means we
			// can't do more than 8K fragments per buffer. Cut this in half,
			// and only allow 4096 fragments per buffer. If we are instancing
			// then the buffers only hold a single point per instance, so
			// allow 32K fragments.
			var maxSize = useInstancing ? 32768 : 4096;
			var i;
			for(i = 0; i < fragIds.length; ++i) {
				var fragIdList = fragIds[i];
				if(fragIdList && fragIdList.length > 0) {
					counts[i] = threshold;
					++visibleCount;
					var occlusionMaterial = _occlusionMaterials[useInstancing][i];
					var length = fragIdList.length;
					var start = 0,
						end;
					for(; start < length; start += end) {
						end = Math.min(maxSize, length - start);

						// Build buffer for the fragment boxes
						var geometry = useInstancing ? createInstancedBBoxGeometry(boxes, fragIdList, start, end) :
							createBBoxGeometry(boxes, fragIdList, start, end);
						var mesh = new THREE.Mesh(geometry, occlusionMaterial);
						mesh.frustumCulled = false;
						_occlusionScene.add(mesh);
					}
				}
			}

			// Clear render target
			if(!_occlusionTarget)
				createOcclusionTarget();
			_renderer.setClearColor(_white, 1);

			// Render the scene
			_renderer.setRenderTarget(_occlusionTarget);
			_renderer.clear(true, false, false);
			_renderer.render(_occlusionScene, _camera, _occlusionTarget, false, null);

			// Some cleanup
			_renderer.clearBlend();
			_occlusionScene.children.forEach(function(mesh) {
				mesh.geometry.dispose();
			});
			_occlusionScene.remove.apply(_occlusionScene, _occlusionScene.children); // Remove all children from scene

			// For debugging, show occlusion target for some pack files
			if(showOcclusion[packIds[0]] || showOcclusion[packIds[1]] || showOcclusion[packIds[2]] || showOcclusion[packIds[3]])
				this.getRenderTargetPixels('occlusion');

			// Get the result.
			if(!_occlusionTest)
				_occlusionTest = new Uint8Array(_settings.deviceWidth * 4 * _settings.deviceHeight);
			_renderer.readRenderTargetPixels(_occlusionTarget, 0, 0, _settings.deviceWidth, _settings.deviceHeight, _occlusionTest);

			// Look for pixels.
			switch(fragIds.length) {
				case 1:
					for(i = _occlusionTest.length; visibleCount > 0 && (i -= 4) >= 0;) {
						if(!_occlusionTest[i]) {
							counts[0] -= 1;
							visibleCount -= !counts[0];
						}
					}
					return Promise.resolve([counts[0] <= 0]);
				case 2:
					for(i = _occlusionTest.length; visibleCount > 0 && (i -= 4) >= 0;) {
						if(!_occlusionTest[i]) {
							counts[0] -= 1;
							visibleCount -= !counts[0];
						}
						if(!_occlusionTest[i + 1]) {
							counts[1] -= 1;
							visibleCount -= !counts[1];
						}
					}
					return Promise.resolve([counts[0] <= 0, counts[1] <= 0]);
				case 3:
					for(i = _occlusionTest.length; visibleCount > 0 && (i -= 4) >= 0;) {
						if(!_occlusionTest[i]) {
							counts[0] -= 1;
							visibleCount -= !counts[0];
						}
						if(!_occlusionTest[i + 1]) {
							counts[1] -= 1;
							visibleCount -= !counts[1];
						}
						if(!_occlusionTest[i + 2]) {
							counts[2] -= 1;
							visibleCount -= !counts[2];
						}
					}
					return Promise.resolve([counts[0] <= 0, counts[1] <= 0, counts[2] <= 0]);
				case 4:
					for(i = _occlusionTest.length; visibleCount > 0 && (i -= 4) >= 0;) {
						if(!_occlusionTest[i]) {
							counts[0] -= 1;
							visibleCount -= !counts[0];
						}
						if(!_occlusionTest[i + 1]) {
							counts[1] -= 1;
							visibleCount -= !counts[1];
						}
						if(!_occlusionTest[i + 2]) {
							counts[2] -= 1;
							visibleCount -= !counts[2];
						}
						if(!_occlusionTest[i + 3]) {
							counts[3] -= 1;
							visibleCount -= !counts[3];
						}
					}
					return Promise.resolve([counts[0] <= 0, counts[1] <= 0, counts[2] <= 0, counts[3] <= 0]);
			}
		};

		this.setStencilEnabled = function(enable) {
			_useStencil = _hasStencil && enable;
			_renderer.state.buffers.stencil.setTest(enable);
			var gl = _renderer.context;
			_renderer.state.buffers.stencil.setOp(gl.KEEP, gl.KEEP, enable ? gl.REPLACE : gl.KEEP);
		};

		this.clearAllOverlays = function() {
			_renderer.clearTarget(_overlayTarget, true, false, false);
		};

		this.renderOverlays = function(overlays, lights) {
			var haveOverlays = 0;

			_isRenderingOverlays = true;

			for(var key in overlays) {
				var p = overlays[key];
				var s = p.scene;
				var c = p.camera ? p.camera : _camera;
				if(s.children.length) {

					if(!haveOverlays) {
						haveOverlays = 1;

						//clear the overlay target once we see
						//the first non-empty overlay scene
						_renderer.setClearColor(_black, 0.0);
						_renderer.clearTarget(_overlayTarget, true, false, false);
					}

					//NOTE: This logic renders the top side of the highlighted objects first,
					//and then the bottom side. The reason is that the top side material is opaque,
					//while we want to render the hidden parts of the object with faint transparency.
					//For objects that covers themselves and are also covered by other objects
					//this is a problem, since the opaque parts would prevent the back parts from showing.

					//However, edge rendering uses painter's algorithm settings for the depth,
					//since we don't care to show hidden edges from under top edges.

					//Render top side of the object using the primary highlight material
					if(p.materialPre) {
						s.overrideMaterial = p.materialPre;
					}
					_renderer.render(s, c, _overlayTarget, false, lights);

					if(p.materialPost) {
						//render hidden edges
						_isRenderingHidden = true; //flag used when getting the correct override material for the hidden pass
						_renderer.context.depthFunc(_renderer.context.GREATER);

						if(_renderEdges) {
							_edgeMaterial.depthWrite = false;
							_edgeMaterial.depthTest = false;
							s.overrideMaterial = _edgeMaterial;
							_renderer.render(s, c, _overlayTarget, false);
						}

						//Render bottom side of the object
						//for selection that's done using light transparency to show
						//areas the object spans under other objects
						s.overrideMaterial = p.materialPost;
						_renderer.render(s, c, _overlayTarget, false, lights);

						_renderer.context.depthFunc(_renderer.context.LEQUAL);
						_isRenderingHidden = false;
					}

					//Render top side edges last
					if(_renderEdges && p.materialPre) {
						_edgeMaterial.depthWrite = false;
						_edgeMaterial.depthTest = true;
						s.overrideMaterial = _edgeMaterial;
						_renderer.render(s, c, _overlayTarget, false);
					}

					s.overrideMaterial = null;
				}
			}

			//Back to normal edge mode
			_isRenderingOverlays = false;
			_edgeMaterial.depthWrite = true;
			_edgeMaterial.depthTest = true;

			// Combine selection highlights with overlays
			if(_blendHighlight) {
				// If there isn't anything else in the overlay, then we should clear it.
				if(!haveOverlays) {
					haveOverlays = 1;

					//If we need to blend in the highlights, then clear the overlay, if it wasn't before.
					_renderer.setClearColor(_black, 0.0);
					_renderer.clearTarget(_overlayTarget, true, false, false);
				}

				// We need to clear the visible highlight where it was overwritten.
				var stencil = _renderer.state.buffers.stencil;
				stencil.setFunc(_renderer.context.EQUAL, 0, 1);
				stencil.setTest(true);
				_highlightClearPass.render(_renderer, _highlightTargets[1], null);
				stencil.setTest(false);

				// Now blend the highlight targets under the overlay
				// The source targets are set in updateHighlightTargets().
				_highlightBlendPass.render(_renderer, _overlayTarget, null);
			}

			_blendPass.uniforms['useOverlay'].value = haveOverlays;
		};

		// Takes color buffer, uses normal and depth buffer, puts SSAO shading into _ssaoTarget.
		// _postTarget1 is used along the way to ping-pong and do a separable blur on the results.
		this.computeSSAO = function(skipAOPass) {
			if(!skipAOPass && _settings.sao) {

				//console.time("SAO");
				if(!_saoBufferValid) {
					if(_depthMipMap && _depthMipMap.length) {
						var prevMip = _depthMipMap[0];
						_saoMipFirstPass.uniforms['resolution'].value.set(1.0 / prevMip.width, 1.0 / prevMip.height);
						_saoMipFirstPass.render(_renderer, prevMip, _depthTarget);
						for(var i = 1; i < _depthMipMap.length; i++) {
							var curMip = _depthMipMap[i];
							_saoMipPass.uniforms['resolution'].value.set(1.0 / curMip.width, 1.0 / curMip.height);
							_saoMipPass.render(_renderer, curMip, prevMip);
							prevMip = curMip;
						}
					}
					// compute SSAO and put in _ssaoTarget
					_saoPass.render(_renderer, _ssaoTarget, _colorTarget);

					//console.timeEnd("SAO");
					//console.time("SAOblur");
					//Do the separable blur, horizontal and vertical
					_saoBlurPass.uniforms['axis'].value.set(1, 0);
					_saoBlurPass.render(_renderer, _postTarget1, _ssaoTarget);
					_saoBlurPass.uniforms['axis'].value.set(0, 1);
					_saoBlurPass.render(_renderer, _ssaoTarget, _postTarget1);

					_saoBufferValid = true;
				}

				_blendPass.uniforms['useAO'].value = 1;
				//console.timeEnd("SAOblur");
			} else {
				// Ensure that any previous SSAO computation post-process target is not blended in.
				_blendPass.uniforms['useAO'].value = 0;
			}

		};

		function saveOverlayAndHighlightUniforms() {
			var hold = [_blendPass.uniforms['useOverlay'].value, _blendPass.uniforms['highlightRange'].value, _blendPass.uniforms['objID'].value];
			_blendPass.uniforms['useOverlay'].value = 0;
			_blendPass.uniforms['highlightRange'].value = 0;
			_blendPass.uniforms['objID'].value = 0;
			return hold;
		}

		function restoreOverlayAndHighlightUniforms(hold) {
			_blendPass.uniforms['useOverlay'].value = hold[0];
			_blendPass.uniforms['highlightRange'].value = hold[1];
			_blendPass.uniforms['objID'].value = hold[2];
		}

		function saveSAOUniform() {
			var hold = _blendPass.uniforms['useAO'].value;
			_blendPass.uniforms['useAO'].value = 0;
			return hold;
		}

		function restoreSAOUniform(hold) {
			_blendPass.uniforms['useAO'].value = hold;
		}

		function blendAndPostProcess() {
			var outTarget = _postTarget1;
			var inTarget = _colorTarget;
			if(_blendPass.uniforms['useAO'].value) {
				var hold = saveOverlayAndHighlightUniforms();
				_blendPass.render(_renderer, outTarget, inTarget);
				inTarget = outTarget;
				outTarget = _postTarget2;
				restoreOverlayAndHighlightUniforms(hold);
			}
			_postProcPass.render(_renderer, outTarget, inTarget);
			inTarget = outTarget;
			if(outTarget === _postTarget1) {
				outTarget = _postTarget2;
			} else {
				outTarget = _postTarget1;
			}
			if(_blendPass.uniforms['useOverlay'].value ||
				_blendPass.uniforms['highlightRange'].value ||
				_blendPass.uniforms['objID'].value) {
				var hold = saveSAOUniform();
				_blendPass.render(_renderer, outTarget, inTarget);
				inTarget = outTarget;
				restoreSAOUniform(hold);
			}
			// the inTarget is always set to the previous outTarget after a pass is done
			return inTarget;
		}
		// userFinalPass is used by stereo rendering, giving the context to use for where the render should be put.
		// If no context is given, the default frame buffer is used.
		this.presentBuffer = function(userFinalPass) {

			if(!_renderer)
				return;

			//See if the blend pass is trivial 1:1, in which
			//case we can just use the main color target for
			//the final pass and skip the blend pass.
			//NOTE: This needs to be adjusted if the blend pass ever
			//does the tone mapping again.
			//TODO: Another possible improvement is to support blending of the SAO
			//inside the FXAA pass, in case the blend pass is just modulating by the AO value.
			var canSkipBlendPass = !_blendPass.uniforms['useAO'].value &&
				!_blendPass.uniforms['useOverlay'].value &&
				// idAtPixel can return -1 for the ID when nothing is there
				(_lastHighlightId === 0 || _lastHighlightId === -1) &&
				(_lastHighlightModelId === 0 || _lastHighlightModelId === -1);

			// In this code, the following inputs cannot be written to:
			// _colorTarget holds the current "normal" render.
			// _ssaoTarget holds the SSAO results to be blended in, but can be wiped out by other modes.

			// What uses what (_colorTarget is always used)
			// Blend    Antialias   PostProc    UserPass
			// .        .           .           .           - simple case, just copy
			// X        .           .           .           - blend to frame buffer
			// .        X           .           .           - fxaa to frame buffer
			// X        X           .           .           - _postTarget1
			// .        .           X           .           - _postTarget1
			// X        .           X           .           - _postTarget1, _postTarget2
			// .        X           X           .           - _postTarget1, _postTarget2
			// X        X           X           .           - _postTarget1, _postTarget2, _postProcDisplayTarget
			// .        .           .           X           - _postTarget1
			// X        .           .           X           - _postTarget1, _postTarget2
			// .        X           .           X           - _postTarget1
			// X        X           .           X           - _postTarget1, _postTarget2
			// .        .           X           X           - *not supported*
			// X        .           X           X           - *not supported*
			// .        X           X           X           - *not supported*
			// X        X           X           X           - *not supported*

			if(canSkipBlendPass) {
				// we can use the color target for the final pass and not bother with blending in SAO or the overlay or highlighting

				if(_settings.antialias) {
					// antialiasing is on

					if(userFinalPass) {
						// post processing is currently not valid for stereo viewing TODO
						// if (_settings.postProcShaded) {
						//     // FXAA is put in post target 1 - TODO no post processing
						//     _fxaaPass.render(_renderer, _postTarget1, _colorTarget);
						//     // and copied and downsized to the context's frame buffer
						//     userFinalPass.render(_renderer, userFinalPass, _postTarget1);
						// } else {
						// FXAA is put in post target 1
						_fxaaPass.render(_renderer, _postTarget1, _colorTarget);
						// and copied to the context's frame buffer
						userFinalPass.render(_renderer, null, _postTarget1);
					} else {
						if(_settings.postProcShaded) {
							// post-processing is done, then fxaa is done and copied to framebuffer
							// bindings need to be cleared on mode change, else you get LMV-2848,
							// warnings about input and output being the same target.
							_postProcPass.render(_renderer, _postTarget1, _colorTarget);
							_copyPass.render(_renderer, _postProcDisplayTarget, _postTarget1);
							_fxaaPass.render(_renderer, null, _postProcDisplayTarget);
						} else {
							// just fxaa is needed: apply and put in frame buffer
							_fxaaPass.render(_renderer, null, _colorTarget);
						}
					}
				}
				// no antialiasing
				else if(userFinalPass) {
					// just copy to given context - currently not valid to use stereo viewing
					userFinalPass.render(_renderer, null, _colorTarget);
				} else if(_settings.postProcShaded) {
					// post-process the color target, put results in post target 1
					// bindings need to be cleared on mode change, else you get LMV-2848,
					// warnings about input and output being the same target.
					_postProcPass.render(_renderer, _postTarget1, _colorTarget);
					// and copy and downsize this result to the display frame buffer
					_copyPass.render(_renderer, null, _postTarget1);
				} else {
					// simply copy the color target to the frame buffer
					_copyPass.render(_renderer, null, _colorTarget);
				}

			} else {
				// Blending of some content must be done.
				//console.time("post");
				//If we have fxaa, do the blending into an offscreen target
				//then FXAA into the final target
				if(_settings.antialias) {
					// antialiasing and blending

					if(userFinalPass) {
						// apply fxaa and put to given context's frame buffer - does not include post-processing TODO
						// first blend in content in ssao target, overlay, ID, as needed, and put it in post target 1
						_blendPass.render(_renderer, _postTarget1, _colorTarget);

						_fxaaPass.render(_renderer, _postTarget2, _postTarget1);
						userFinalPass.render(_renderer, null, _postTarget2);
					} else if(_settings.postProcShaded) {
						// post-process and fxaa
						// bindings need to be cleared on mode change, else you get LMV-2848,
						// warnings about input and output being the same target.
						// first blend in content in ssao target, overlay, ID, as needed, and put it in post target 1

						var inTarget = blendAndPostProcess();
						_copyPass.render(_renderer, _postProcDisplayTarget, inTarget);
						_fxaaPass.render(_renderer, null, _postProcDisplayTarget);
					} else {
						// antialias the blended image
						// first blend in content in ssao target, overlay, ID, as needed, and put it in post target 1
						_blendPass.render(_renderer, _postTarget1, _colorTarget);
						_fxaaPass.render(_renderer, null, _postTarget1);
					}
				} else {
					// no antialiasing, just blending

					if(userFinalPass) {
						// blend into post target 1 and copy over for output
						_blendPass.render(_renderer, _postTarget1, _colorTarget);
						userFinalPass.render(_renderer, null, _postTarget1);
					} else {
						// post-process and blend, OR just blend
						if(_settings.postProcShaded) {
							// bindings need to be cleared on mode change, else you get LMV-2848,
							// warnings about input and output being the same target.
							var inTarget = blendAndPostProcess();
							// and copy and downsize this result to the frame buffer
							_copyPass.render(_renderer, null, inTarget);
						} else {
							_blendPass.render(_renderer, null, _colorTarget);
						}
					}
				}
			}

		};

		this.composeFinalFrame = function(skipAOPass, skipPresent) {
			//Apply the post pipeline and then show to screen.
			//Note that we must preserve the original color buffer
			//so that we can update it progressively

			// always called, so that useAO is set to 0 if not in use.
			this.computeSSAO(skipAOPass);

			if(!skipPresent)
				this.presentBuffer();

			//console.timeEnd("post");

		};

		this.cleanup = function() {
			if(_colorTarget) {
				_colorTarget.dispose();
				_colorTarget = null;
			}

			if(_depthTarget) {
				_depthTarget.dispose();
				_depthTarget = null;
			}

			if(_overlayTarget) {
				_overlayTarget.dispose();
				_overlayTarget = null;
			}

			if(_postTarget1) {
				_postTarget1.dispose();
				_postTarget1 = null;
			}

			if(_ssaoTarget) {
				_ssaoTarget.dispose();
				_ssaoTarget = null;
			}

			if(_postTarget2) {
				_postTarget2.dispose();
				_postTarget2 = null;
			}

			if(_depthMipMap) {
				for(var i = 0; i < _depthMipMap.length; i++) {
					_depthMipMap[i].dispose();
				}

				_depthMipMap = [];
			}

			if(_occlusionTarget) {
				_occlusionTarget.dispose();
				_occlusionTarget = null;
			}

			_occlusionTest = null;
		};

		// returns 1 if any edging is on
		this.postProcessEdgesOn = function() {
			return(_postProcPass.uniforms['idEdges'].value !== 0 ||
				_postProcPass.uniforms['normalEdges'].value !== 0 ||
				_postProcPass.uniforms['depthEdges'].value !== 0);
		};

		// This code assumes the overlay target is always present and matches the color buffer if the color buffer is created.
		var updateHighlightTargets = function() {
			// First figure out how many highlight buffers we need
			var length = 0;
			if(_overlayTarget) {
				_selectionMaterials.forEach(function(material) {
					length = Math.max(length, (material.target | 0) + 1);
				});
			}

			// If it doesn't change then we are done
			var oldLength = _highlightTargets.length;
			var end = Math.max(length, oldLength);
			for(var i = 0; i < end; ++i) {
				var target = i < oldLength ? _highlightTargets[i] : null;
				if(i >= oldLength) {
					// New targets are needed, push them onto the array
					target = _overlayTarget.clone();
					_highlightTargets[i] = target;
					target.name = "highlight " + i;
				} else if(i >= length) {
					// Old targets are not needed, dispose of them.
					target.dispose();
					target = null;
				} else if(target.shareDepthFrom !== _overlayTarget.shareDepthFrom) {
					// An old target is needed, but doesn't using the right depth/stencil buffers
					// dispose of the old target and make a new one
					target.dispose();
					target = _overlayTarget.clone();
					_highlightTargets[i] = target;
					target.name = "highlight " + i;
				}
				var uniform = _highlightBlendPass.uniforms['tHighlight' + i];
				if(uniform && uniform.value !== target) {
					uniform.value = target;
					_blendPass.material.needsUpdate = true;
				}
			}

			// Set the new array length
			_highlightTargets.length = length;
		};

		this.setSize = function(w, h, force, suppress) {

			_w = w;
			_h = h;

			_settings.logicalWidth = w;
			_settings.logicalHeight = h;

			//Just a way to release the targets in cases when
			//we use a custom render context and don't need this one
			//temporarily
			if((w === 0 && h === 0) || !_renderer) {
				this.cleanup();
				return;
			}

			var sw = 0 | (w * _renderer.getPixelRatio());
			var sh = 0 | (h * _renderer.getPixelRatio());

			_settings.deviceWidth = sw;
			_settings.deviceHeight = sh;

			// normally, render() calls setRenderTarget, which properly sets the size to be
			// the correct viewport for rendering. However, setAOEnabled also calls this
			// method, to allocate or deallocate the various SSAO buffers, etc. Because
			// post processing can increase the size of the target by 2x (code below),
			// we do not want to have setAOEnabled touch the renderer's setSize. Long and
			// short, setAOEnabled sends in "suppress" as true. LMV-2863
			if(!suppress) {
				_renderer.setSize(w, h);
			}

			//zvp.logger.log("width: " + sw + " height: " + sh);

			var i;

			var orig_sw = sw;
			var orig_sh = sh;

			// supersample antialiasing, or post-processed edges, which need a higher resolution;
			// if a mobile device, don't scale up by 2x for post-processing, as this would take a lot of memory and may cause mobile to fail. TODO - true?
			if(_settings.useSSAA || (_settings.postProcShaded && !_isWeakDevice && _renderer.getPixelRatio() <= 1) && this.postProcessEdgesOn()) {
				/*
				    //Create a somewhat larger render target, that is power of 2 size and has mipmap
				    sw *= 3 / _renderer.getPixelRatio();
				    sh *= 3 / _renderer.getPixelRatio();

				    var w = 1;
				    while (w < sw) w *= 2;
				    var h = 1;
				    while (h < sh) h *= 2;

				    sw = w;
				    sh = h;
				    */
				sw *= 2;
				sh *= 2;

				//force = true;
			}

			var resX = 1.0 / sw;
			var resY = 1.0 / sh;

			//Just the regular color target -- shares depth buffer
			//with the depth target.
			if(force || !_colorTarget || _colorTarget.width != sw || _colorTarget.height != sh) {

				zvp.logger.log("Reallocating render targets.");
				this.cleanup();

				_colorTarget = new THREE.WebGLRenderTarget(sw, sh, {
					minFilter: THREE.LinearFilter,
					magFilter: THREE.LinearFilter,
					format: THREE.RGBFormat,
					type: _settings.useHdrTarget ? THREE.FloatType : THREE.UnsignedByteType,
					//anisotropy: Math.min(this.getMaxAnisotropy(), 4),
					stencilBuffer: _hasStencil
				});
				// three.js has a flaw in its constructor: the generateMipmaps value is always initialized to true
				_colorTarget.generateMipmaps = false;
				_colorTarget.name = "colorTarget";

				_overlayTarget = new THREE.WebGLRenderTarget(sw, sh, {
					minFilter: THREE.NearestFilter,
					magFilter: THREE.NearestFilter,
					format: THREE.RGBAFormat,
					stencilBuffer: _hasStencil
				});
				_overlayTarget.generateMipmaps = false;
				_overlayTarget.name = "overlayTarget";

				_overlayTarget.shareDepthFrom = _colorTarget;

				updateHighlightTargets();

				_depthTarget = null;
				_postTarget1 = null;
				_postProcDisplayTarget = null;
				_ssaoTarget = null;
				_postTarget2 = null;
				_depthMipMap = [];
			}

			if(isRenderTargetUsed(zvp.RenderTargets.Post1)) {
				if(force || !_postTarget1 || _postTarget1.width != sw || _postTarget1.height != sh) {
					//We need one extra post target if FXAA is on, so
					//to use as intermediate from Blend->FXAA pass.
					_postTarget1 = new THREE.WebGLRenderTarget(sw, sh, {
						minFilter: THREE.LinearFilter,
						magFilter: THREE.LinearFilter,
						format: THREE.RGBAFormat,
						//anisotropy: 0,
						//anisotropy: Math.min(this.getMaxAnisotropy(), 4),
						stencilBuffer: false,
						depthBuffer: false
					});
					_postTarget1.generateMipmaps = false;
					_postTarget1.name = "postTarget1";
				}
			}

			// note that these are used only if _postTarget1 is also used, so _postTarget1 will exist
			if(!_ssaoTarget && isRenderTargetUsed(zvp.RenderTargets.SSAO)) {
				_ssaoTarget = _postTarget1.clone();
				_ssaoTarget.name = "SSAO target";
			}

			if(!_postTarget2 && isRenderTargetUsed(zvp.RenderTargets.Post2)) {
				_postTarget2 = _postTarget1.clone();
				_postTarget2.name = "post target 2";
			}

			if(!_postProcDisplayTarget && isRenderTargetUsed(zvp.RenderTargets.PostDisplay)) {
				// final-image sized intermediate buffer, so antialiasing can be done correctly.
				_postProcDisplayTarget = new THREE.WebGLRenderTarget(orig_sw, orig_sh, {
					minFilter: THREE.LinearFilter,
					magFilter: THREE.LinearFilter,
					format: THREE.RGBAFormat,
					//anisotropy: 0,
					//anisotropy: Math.min(this.getMaxAnisotropy(), 4),
					stencilBuffer: false,
					depthBuffer: false
				});
				_postProcDisplayTarget.generateMipmaps = false;
				_postProcDisplayTarget.name = "postTargetNormal";
			}

			if(isRenderTargetUsed(zvp.RenderTargets.Depth)) {
				if(force || !_depthTarget || _depthTarget.width != sw || _depthTarget.height != sh) {

					_depthTarget = createDepthTarget(sw, sh, _depthTargetFormat, _depthTargetType, _colorTarget);

					//SSAO depth/normals mip maps. Those are "manually" created
					//because we use custom sampling. Also, they are separately bound into
					//the shader because there doesn't seem to be an easy way to load them
					//as mip levels of the same texture, in the case they were render buffers initially.
					_depthMipMap = [];
					for(var j = 0; j < 5; j++) {
						var mip = new THREE.WebGLRenderTarget(0 | (sw / (2 << j)), 0 | (sh / (2 << j)), {
							minFilter: THREE.NearestFilter,
							magFilter: THREE.NearestFilter,
							format: THREE.RGBAFormat,
							//type:THREE.FloatType,
							depthBuffer: false,
							stencilBuffer: false
						});
						mip.generateMipmaps = false;
						_depthMipMap.push(mip);
						_saoPass.uniforms['tDepth_mip' + (j + 1)].value = mip;
					}

					//Re-check this when render targets change
					_mrtFloat32Works = _renderer.verifyMRTWorks([_colorTarget, _depthTarget]);
				}

				_saoPass.uniforms['size'].value.set(sw, sh);
				_saoPass.uniforms['resolution'].value.set(resX, resY);
				_saoPass.uniforms['tDepth'].value = _depthTarget;

				_saoBlurPass.uniforms['size'].value.set(sw, sh);
				_saoBlurPass.uniforms['resolution'].value.set(resX, resY);

				_postProcPass.uniforms['tDepth'].value = _depthTarget;
			}

			if(isRenderTargetUsed(zvp.RenderTargets.ModelId)) {
				if(force || !_idTargets[0] || _idTargets[0].width != sw || _idTargets[0].height != sh) {
					for(i = 0; i < _idTargets.length; i++) {
						_idTargets[i] && _idTargets[i].dispose();
					}
					_idTargets = [];
					for(i = 0; i < _settings.numIdTargets; i++) {
						var target = createRenderTarget(zvp.RenderTargets.ModelId, sw, sh);
						target.name = "id " + i;
						_idTargets.push(target);
					}

					//Re-check this when render targets change
					_mrtRGBA8Works = _renderer.verifyMRTWorks([_colorTarget].concat(_idTargets));
					if(!_mrtRGBA8Works) {
						zvp.logger.warn("ID buffer requested, but MRT is not supported. Some features will not work.");
					}

					_occlusionIds = new Uint8Array(4 * _idTargets[0].width * _idTargets[0].height);
				}

				_postProcPass.uniforms['tID'].value = _idTargets[0];
				_postProcPass.uniforms['tID'].value = _idTargets[0];

			} else if(_idTargets[0]) {
				_occlusionIds = null;
				for(i = 0; i < _idTargets.length; i++) {
					_idTargets[i].dispose();
					_idTargets[i] = null;
				}
				// make sure no _idTargets are defined, since they've been released. LMV-2691
				_idTargets.length = 0;
			}

			_fxaaPass.uniforms['uResolution'].value.set(resX, resY);
			_postProcPass.uniforms['resolution'].value.set(resX, resY);

			_blendPass.uniforms['tOverlay'].value = _overlayTarget;
			_blendPass.uniforms['tAO'].value = _ssaoTarget;
			_blendPass.uniforms['useAO'].value = _settings.sao ? 1 : 0;
			_blendPass.uniforms['resolution'].value.set(resX, resY);
			_blendPass.uniforms['tID'].value = _idTargets[0] || null;
			_blendPass.uniforms['tID2'].value = _idTargets[1] || null;

		};

		this.getMaxAnisotropy = function() {
			return _renderer ? _renderer.getMaxAnisotropy() : 0;
		};

		// HACK: returns MRT flags required by this render context
		// so that the flags can be passed to the material manager
		this.mrtFlags = function() {
			return {
				mrtNormals: _mrtFloat32Works && isRenderTargetUsed(zvp.RenderTargets.Depth),
				mrtIdBuffer: (_mrtRGBA8Works && isRenderTargetUsed(zvp.RenderTargets.ModelId)) ? _settings.numIdTargets : undefined
			};
		};

		/**
		 * Adds/Removes and id frame buffer.
		 * Supports only 1 or 2 framebuffers. Default is 1.
		 * 
		 * @param {Number} value - id targets. Accepts only values 1 or 2. Default is 1.
		 */
		this.setIdTargetCount = function(value) {
			if(value > 2 || value < 1) return;
			if(value === _settings.numIdTargets) return;

			_settings.numIdTargets = value;
			if(_idTargets.length === 0)
				return;

			//
			// Disabled because there is no real benefit.
			//
			//if (value === 1 && _idTargets.length.length === 2) {
			//    // Remove the model id target
			//    _idTargets[1].dispose();
			//    _idTargets[1] = null;
			//    _idTargets.length = 1;
			//    _blendPass.uniforms[ 'tID2' ].value = null;
			//    delete _blendPass.material.defines.USE_MODEL_ID;
			//    _blendPass.material.needsUpdate = true;
			//    return true;
			//};

			if(value === 2 && _idTargets.length === 1) {
				// Add the model id target
				var sw = _idTargets[0].width;
				var sh = _idTargets[0].height;
				var newTarget = createRenderTarget(zvp.RenderTargets.ModelId, sw, sh);
				newTarget.name = "id " + _idTargets.length;
				_idTargets.push(newTarget);
				_blendPass.uniforms['tID2'].value = newTarget;
				_blendPass.material.defines.USE_MODEL_ID = "";
				_blendPass.material.needsUpdate = true;
				return true;
			}
		};

		this.getAntialiasing = function() {
			return _settings.antialias;
		};

		this.initPostPipeline = function(useSAO, useFXAA) {

			//TODO: Do we want to move the IE check to higher level code?
			_settings.sao = useSAO && !zv.isIE11 && _depthTargetSupported;
			_settings.antialias = useFXAA && !zv.isIE11;

			if(_settings.haveTwoSided) {
				forEachDepthMaterial(function(mat) {
					mat.side = THREE.DoubleSide;
				});
			}

			//TODO: do we really need to update all these or just the depthMaterial?
			forEachDepthMaterial(function(mat) {
				mat.needsUpdate = true;
			});
			_saoPass.material.needsUpdate = true;
			_saoBlurPass.material.needsUpdate = true;
			_saoMipFirstPass.material.needsUpdate = true;
			_saoMipPass.material.needsUpdate = true;
			_fxaaPass.material.needsUpdate = true;
			_postProcPass.material.needsUpdate = true;
			_blendPass.material.needsUpdate = true;
			_clearPass.material.needsUpdate = true;
			_copyPass.material.needsUpdate = true;

			//Also reallocate the render targets
			this.setSize(_w, _h);
		};

		this.setClearColors = function(colorTop, colorBot) {
			if(!colorBot) {
				_clearColor = colorTop.clone();
			}
			//If the gradient is trivial, we can use a simple clear instead.
			else if(colorTop.equals(colorBot) || _isWeakDevice) {
				_clearColor = new THREE.Color(
					0.5 * (colorTop.x + colorBot.x),
					0.5 * (colorTop.y + colorBot.y),
					0.5 * (colorTop.z + colorBot.z));
			} else {
				_clearColor = undefined;
			}

			if(!_clearColor) {
				_clearPass.uniforms.color1.value.copy(colorTop);
				_clearPass.uniforms.color2.value.copy(colorBot);
			}
		};

		this.setAOEnabled = function(enabled) {
			_settings.sao = enabled && _depthTargetSupported;
			// recreate required buffers when sao is turned on; do not reset rendering size
			this.setSize(_w, _h, false, true);
		};

		this.setAOOptions = function(radius, intensity, opacity) {

			if(radius !== undefined) {
				_saoPass.uniforms['radius'].value = radius;

				// It is questionable whether this "isMobileDevice()" test should be here.
				// The shader bias is a world distance, not a screen distance. Still, it
				// may fight some precision problem on mobile. The whole radius/bias system
				// is pretty kludgey.
				_saoPass.uniforms['bias'].value = zv.isMobileDevice() ? 0.1 : 0.01;
				// more theoretically sound, but isMobileDevice() is still a little questionable:
				//_saoPass.uniforms[ 'bias' ].value = radius * (zv.isMobileDevice() ? 0.1 : 0.01);
				_saoBlurPass.uniforms['radius'].value = radius;
			}
			if(intensity !== undefined) {
				_saoPass.uniforms['intensity'].value = intensity;
			}
			//Opacity handles undefined differently (it uses default if undefined given)
			//until all user-facing calls to setAOOptions can handle the new opacity setting.
			if(opacity !== undefined) {
				_blendPass.uniforms['aoOpacity'].value = opacity;
			} else {
				_blendPass.uniforms['aoOpacity'].value = 1.0;
			}
			_saoBufferValid = false;
		};

		this.getAOEnabled = function() {
			return _settings.sao;
		};

		this.getAORadius = function() {
			return _saoPass.uniforms['radius'].value;
		};

		this.getAOIntensity = function() {
			return _saoPass.uniforms['intensity'].value;
		};

		this.setCubeMap = function(map) {
			_clearPass.material.envMap = map;
			if(!map)
				this.toggleEnvMapBackground(false);
		};

		this.setEnvRotation = function(rotation) {
			_envRotation = rotation;
			_clearPass.material.envRotationSin = Math.sin(rotation);
			_clearPass.material.envRotationCos = Math.cos(rotation);
		};

		this.getEnvRotation = function() {
			return _envRotation;
		};

		this.setEnvExposure = function(exposure) {
			_clearPass.uniforms['envMapExposure'].value = Math.pow(2.0, exposure);

			//The renderer overwrites the uniform's value based on the material's
			//property in refreshUniformsIBL, so set it there too.
			_clearPass.material.envMapExposure = Math.pow(2.0, exposure);
			_clearPass.material.needsUpdate = true;
		};

		this.setTonemapExposureBias = function(bias) {
			_exposureBias = bias;

			_clearPass.uniforms['exposureBias'].value = Math.pow(2.0, bias);

			//_blendPass.uniforms['exposureBias'].value = Math.pow(2.0, bias);
		};

		this.getExposureBias = function() {
			return _exposureBias;
		};

		//Required for switching camera for stereo rendering
		this.setCamera = function(camera) {
			_camera = camera;
		};

		this.setTonemapMethod = function(value) {

			_tonemapMethod = value;

			if(value === 0) {
				/*
				    if (_settings.useHdrTarget) {
				        //reallocate the render target if we are going from hdr to ldr
				        _settings.useHdrTarget = false;
				        this.setSize(_w, _h, true);
				    }
				    */
				_renderer.gammaInput = false;
			} else {
				/*
				    if (!_settings.useHdrTarget) {
				        //reallocate the render target if we are going from hdr to ldr
				        _settings.useHdrTarget = true;
				        this.setSize(_w, _h, true);
				    }
				*/
				//Tell the renderer to linearize all material colors
				_renderer.gammaInput = true;
			}

			_clearPass.material.tonemapOutput = _tonemapMethod;
			_clearPass.material.needsUpdate = true;

			// _blendPass.uniforms['toneMapMethod'].value = value;

		};

		this.getToneMapMethod = function() {
			return _tonemapMethod;
		};

		this.toggleTwoSided = function(isTwoSided) {

			//In case the viewer encounters two-sided materials
			//it will let us know, so that we can update
			//the override material used for the SAO G-buffer to also
			//render two sided.
			if(_settings.haveTwoSided != isTwoSided) {
				if(_depthMaterial) {
					forEachDepthMaterial(function(mat) {
						mat.side = isTwoSided ? THREE.DoubleSide : THREE.FrontSide;
						mat.needsUpdate = true;
					});
				}
			}
			_settings.haveTwoSided = isTwoSided;
		};

		this.toggleEdges = function(state) {
			_renderEdges = state;
		};

		this.preloadPostProcessStyle = function(style) {
			if(style == undefined) {
				// if no argument given, load them all
				this.preloadPostProcessStyle("graphite");
				this.preloadPostProcessStyle("pencil");
				return;
			}
			switch(style) {
				case "graphite":
					if(_graphiteMaps[0] === undefined) { // TODO better way to test? Note it differs from the one below
						// LMV-2820 fix - we are in control of the URL, so to have Ninja function, we allow load from "another" site.
						THREE.ImageUtils.crossOrigin = '';
						for(var i = 0; i < 8; i++) {
							var file = ZhiUTech.Viewing.Private.getResourceUrl("res/postprocess/Graphite" + (i + 1) + ".png");
							_graphiteMaps[i] = THREE.ImageUtils.loadTexture(file);
							//_graphiteMaps[i] = THREE.ImageUtils.loadTexture("http://localhost:8000/build/res/postprocess/Graphite" + (i+1) + ".png"); 
							_graphiteMaps[i].wrapS = _graphiteMaps[i].wrapT = THREE.RepeatWrapping;
						}
						_postProcPass.uniforms['tGraphite1'].value = _graphiteMaps[0];
						_postProcPass.uniforms['tGraphite2'].value = _graphiteMaps[1];
						_postProcPass.uniforms['tGraphite3'].value = _graphiteMaps[2];
						_postProcPass.uniforms['tGraphite4'].value = _graphiteMaps[3];
						_postProcPass.uniforms['tGraphite5'].value = _graphiteMaps[4];
						_postProcPass.uniforms['tGraphite6'].value = _graphiteMaps[5];
						_postProcPass.uniforms['tGraphite7'].value = _graphiteMaps[6];
						_postProcPass.uniforms['tGraphite8'].value = _graphiteMaps[7];
					}
					break;
				case "pencil":
					if(_pencilMap === null) { // TODO better way to test?
						// LMV-2820 fix - we are in control of the URL, so to have Ninja function, we allow load from "another" site.
						THREE.ImageUtils.crossOrigin = '';
						_pencilMap = THREE.ImageUtils.loadTexture(ZhiUTech.Viewing.Private.getResourceUrl("res/postprocess/ColorPencil_02.png"));
						_pencilMap.wrapS = _pencilMap.wrapT = THREE.RepeatWrapping;
						_pencilBackgroundMap = THREE.ImageUtils.loadTexture(ZhiUTech.Viewing.Private.getResourceUrl("res/postprocess/paper2.jpg"));
						_pencilBackgroundMap.wrapS = _pencilBackgroundMap.wrapT = THREE.RepeatWrapping;

						_postProcPass.uniforms['tFill'].value = _pencilMap;
						_postProcPass.uniforms['tPaper'].value = _pencilBackgroundMap;
					}
					break;
			}
		};

		// returns 1 (or some other error code) on failure, 0 on success
		this.setPostProcessParameter = function(token, value) {

			switch(token) {
				case "style":
					_settings.postProcShaded = false;
					_postProcPass.uniforms['style'].value = WGS.POSTPROC_STYLE_OFF;
					if(_depthTargetSupported) {
						// put this code back in if we can't run with mobile
						// if _isWeakDevice, I guess we can't use? Needs ID buffer and normals/depths.
						// if ( _isWeakDevice ) {
						//     // sorry, not available on mobile - needs ID buffer and normal/depth buffer
						//     return 1;
						// } else {
						// load any textures that haven't been loaded.
						this.preloadPostProcessStyle(value);
						switch(value) {
							case "edging":
								_settings.postProcShaded = true;
								_postProcPass.uniforms['style'].value = WGS.POSTPROC_STYLE_EDGING;
								break;
							case "cel":
								_settings.postProcShaded = true;
								_postProcPass.uniforms['style'].value = WGS.POSTPROC_STYLE_CEL;
								break;
							case "graphite":
								_settings.postProcShaded = true;
								_postProcPass.uniforms['style'].value = WGS.POSTPROC_STYLE_GRAPHITE;
								break;
							case "pencil":
								_settings.postProcShaded = true;
								_postProcPass.uniforms['style'].value = WGS.POSTPROC_STYLE_PENCIL;
								break;
						}
						if(_settings.postProcShaded) {
							_settings.idbuffer = true;
						} else {
							_settings.idbuffer = _enableRolloverHighlight && !_isWeakDevice; // TODO are these good conditions?    
						}

						this.initPostPipeline(_settings.sao, _settings.antialias);
					}
					break;

				case "edges":
					_postProcPass.uniforms['idEdges'].value = value ? 1 : 0;
					_postProcPass.uniforms['normalEdges'].value = value ? 1 : 0;
					_postProcPass.uniforms['depthEdges'].value = value ? 1 : 0;
					// turning off edges means we can use considerably less memory and fragment shading evaluations,
					// i.e., we can use normal-resolution off-screen targets, not 2x2 larger
					this.initPostPipeline(_settings.sao, _settings.antialias);
					break;
				case "idEdges":
					_postProcPass.uniforms['idEdges'].value = value ? 1 : 0;
					this.initPostPipeline(_settings.sao, _settings.antialias);
					break;
				case "normalEdges":
					_postProcPass.uniforms['normalEdges'].value = value ? 1 : 0;
					this.initPostPipeline(_settings.sao, _settings.antialias);
					break;
				case "depthEdges":
					_postProcPass.uniforms['depthEdges'].value = value ? 1 : 0;
					this.initPostPipeline(_settings.sao, _settings.antialias);
					break;
				case "brightness":
					_postProcPass.uniforms['brightness'].value = value;
					break;
				case "contrast":
					_postProcPass.uniforms['contrast'].value = value;
					break;
				case "grayscale":
					_postProcPass.uniforms['grayscale'].value = value ? 1 : 0;
					break;
				case "preserveColor":
					_postProcPass.uniforms['preserveColor'].value = value ? 1 : 0;
					break;
				case "levels":
					_postProcPass.uniforms['levels'].value = value;
					break;
				case "repeats":
					_postProcPass.uniforms['repeats'].value = value;
					break;
				case "rotation": // 0.0 to 1.0, around circle (e.g. 0.5 == pi radians, 1.0 == 2*pi)
					_postProcPass.uniforms['rotation'].value = value;
					break;
				default:
					console.error("setPostProcessParameter: parameter '" + token + "' is not valid.");
			}

			return 0;
		};

		// TODO what's a better return value if undefined? Or just issue a warning? Should there be a separate query function?
		this.queryPostProcessParameter = function(token, value) {
			if(_postProcPass.uniforms[token] !== 'undefined') {
				return _postProcPass.uniforms[token].value;
			} else {
				zvp.logger.warning("queryPostProcessParameter: parameter '" + token + "' is not valid");
				return value;
			}
		};

		this.toggleEnvMapBackground = function(value) {
			_settings.envMapBg = value;
			_clearPass.uniforms.envMapBackground.value = value;
		};

		this.toggleSwapBlackAndWhite = function(value) {

			_settings.swapBlackAndWhite = value;
		};

		this.enter2DMode = function(idMaterial) {
			_idMaterial = idMaterial;
			_oldSettings.sao = _settings.sao;
			_oldSettings.postProcShaded = _settings.postProcShaded;
			_oldSettings.antialias = _settings.antialias;
			_oldSettings.idbuffer = _settings.idbuffer;
			_oldSettings.occlusionid = _settings.occlusionid;
			_settings.idbuffer = true;
			_settings.occlusionid = false;
			_settings.postProcShaded = false;
			_blendPass.material.defines.IS_2D = "";
			this.initPostPipeline(false, false);
		};

		this.exit2DMode = function() {
			_idMaterial = null;
			_settings.idbuffer = _oldSettings.idbuffer && _enableRolloverHighlight;
			_settings.occlusionid = _oldSettings.occlusionid;
			_settings.postProcShaded = _oldSettings.postProcShaded;
			delete _blendPass.material.defines.IS_2D;
			this.initPostPipeline(_oldSettings.sao, _oldSettings.antialias);
		};

		//Returns the value of the ID buffer at the given
		//viewport location. Note that the viewport location is in
		//OpenGL-style coordinates [-1, 1] range.
		//If the optional third parameter is passed in, it's assume to be a two integer array-like,
		//and the extended result of the hit test (including model ID) is stored in it.
		this.idAtPixel = function(vpx, vpy, res) {
			if(!_idTargets[0])
				return 0;

			var px = 0 | ((vpx + 1.0) * 0.5 * _idTargets[0].width);
			var py = 0 | ((vpy + 1.0) * 0.5 * _idTargets[0].height);

			if(_lastIDValid && px === _lastX && py === _lastY) {
				if(res) {
					res[0] = _lastID;
					res[1] = _lastModelID;
				}
				return _lastID;
			}

			_renderer.readRenderTargetPixels(_idTargets[0], px, py, 1, 1, _readbackBuffer);

			var id = (_readbackBuffer[2] << 16) | (_readbackBuffer[1] << 8) | _readbackBuffer[0];
			var modelId = 0;

			if(_idTargets[1]) {
				_renderer.readRenderTargetPixels(_idTargets[1], px, py, 1, 1, _readbackBuffer);

				modelId = (_readbackBuffer[1] << 8) | _readbackBuffer[0];

				//recover negative values when going from 16 -> 32 bits.
				modelId = (modelId << 16) >> 16;

				//Upper byte of 32 bit dbId encoded in the 3rd byte of the model ID target.
				//id = id | (_readbackBuffer[2] << 24);
				//TODO: ouch, the above does not work for 2d sheets, because each mesh contains many objects.
				//Do something about it...
				id = (id << 8) >> 8;

			} else {
				//sign extend the upper byte to get back negative numbers (since we clamp 32 bit to 24 bit when rendering ids)
				id = (id << 8) >> 8;
			}

			_lastX = px;
			_lastY = py;
			_lastID = id;
			_lastModelID = modelId;
			_lastIDValid = true;

			if(res) {
				res[0] = id;
				res[1] = modelId;
			}

			return id;
		};

		this.idAtPixels = function(vpx, vpy, res, result) {
			if(!_idTargets[0])
				return 0;

			var px = (vpx + 1.0) * 0.5 * _idTargets[0].width - (res - 1) * 0.5;
			var py = (vpy + 1.0) * 0.5 * _idTargets[0].height - (res - 1) * 0.5;

			var readbackBuffer = new Uint8Array(4 * res * res);

			_renderer.readRenderTargetPixels(_idTargets[0], px, py, res, res, readbackBuffer);

			var readbackBuffer2 = undefined;
			if(result && _idTargets[1]) {
				readbackBuffer2 = new Uint8Array(4 * res * res);
				_renderer.readRenderTargetPixels(_idTargets[1], px, py, res, res, readbackBuffer2);
			}
			// Start the search at the center of the region and then spiral.
			function spiral() {

				var id;
				var x = 0,
					y = 0;
				var dx = 0,
					dy = -1;

				for(var i = 0; i < res * res; i++) {

					// Translate coordinates with top left as (0, 0)
					var tx = x + (res - 1) / 2;
					var ty = y + (res - 1) / 2;
					if(tx >= 0 && tx <= res && ty >= 0 && ty <= res) {
						var index = tx + ty * res;
						id = (readbackBuffer[4 * index + 2] << 16) | (readbackBuffer[4 * index + 1] << 8) | readbackBuffer[4 * index];

						//sign extend the upper byte to get back negative numbers (since we clamp 32 bit to 24 bit when rendering ids)
						id = (id << 8) >> 8;
						if(id >= 0) {
							if(readbackBuffer2) {
								var modelId = (readbackBuffer2[4 * index + 1] << 8) | readbackBuffer2[4 * index];
								//recover negative values when going from 16 -> 32 bits.
								modelId = (modelId << 16) >> 16;

								result[0] = id;
								result[1] = modelId;
							}
							break;
						}
					}

					if((x == y) || (x < 0 && x == -y) || (x > 0 && x == 1 - y)) {
						var t = dx;
						dx = -dy;
						dy = t;
					}
					x += dx;
					y += dy;
				}

				return id;
			}

			return spiral();

		};

		this.readbackTargetId = function() {
			if(!_idTargets[0])
				return null;

			var readbackBuffer = new Uint8Array(4 * _idTargets[0].width * _idTargets[0].height);
			_renderer.readRenderTargetPixels(_idTargets[0], 0, 0, _idTargets[0].width, _idTargets[0].height, readbackBuffer);

			return {
				buffer: readbackBuffer,
				width: _idTargets[0].width,
				height: _idTargets[0].height
			};
		};

		/**
		 * @private
		 * Shows the content of a render target in a new browser window.
		 * Check to make sure your popup blocker is not blocking the local host.
		 * For debugging purposes only. Typical console command to dump target
		 * to a new browser window:
		 * NOP_VIEWER.impl.renderer().getRenderTargetPixels('color')
		 *
		 * @param targetName {string} Name of render target.
		 *      Can be 'color', 'overlay', 'id', 'post1' or 'post2'.
		 * 
		 * On Safari popups need to be unblocked to see the image.
		 */
		/*
		this.getRenderTargetPixels = function(targetName) {
		    // https://github.com/ebidel/filer.js/blob/master/src/filer.js
		    function dataURLToBlob(dataURL) {
		        var BASE64_MARKER = ';base64,';
		        var parts, contentType, raw;
		        if (dataURL.indexOf(BASE64_MARKER) == -1) {
		            parts = dataURL.split(',');
		            contentType = parts[0].split(':')[1];
		            raw = decodeURIComponent(parts[1]);

		            return new Blob([raw], {type: contentType});
		        }

		        parts = dataURL.split(BASE64_MARKER);
		        contentType = parts[0].split(':')[1];
		        raw = window.atob(parts[1]);
		        var rawLength = raw.length;

		        var uInt8Array = new Uint8Array(rawLength);

		        for (var i = 0; i < rawLength; ++i) {
		            uInt8Array[i] = raw.charCodeAt(i);
		        }

		        return new Blob([uInt8Array], {type: contentType});
		    }

		    // Get the buffer component size
		    function getComponentSize(type) {
		        switch (type) {
		        case THREE.UnsignedByteType:
		            return 1;
		        case THREE.HalfFloatType:
		            return 2;
		        case THREE.FloatType:
		            return 4;
		        }
		        // don't try to support 4444, 5551 or 565
		        return 0;
		    }
		    // Get the buffer format size
		    function getFormatSize(format) {
		        switch (format) {
		        case THREE.RGBAFormat:
		            return 4;
		        case THREE.RGBFormat:
		            return 3;
		        }
		        return 0;
		    }

		    // convert incoming buffer to Uint8ClammpedArray RGBA, which is needed for ImageData
		    function convertBuffer(w, h, buffer) {
		        // Get the buffer format
		        var format = buffer.lmv__format ? buffer.lmv__format.format : THREE.RGBAFormat;
		        var type = buffer.lmv__format ? buffer.lmv__format.type : THREE.UnsignedByteType;
		        var align = buffer.lmv__format ? buffer.lmv__format.align : 4;

		        // Get the component size
		        var size = getComponentSize(type);
		        // Get the format size
		        var len = getFormatSize(format);
		        // If size or len is 0, then the buffer isn't supported.
		        if (size == 0 || len == 0) {
		            zvp.logger.error("getRenderTargetPixels: Only byte and float types are supported");
		            return null;
		        }
		        // If the size is 1 and len is 4, the we already have unsigned byte RGBA,
		        // so just return the Uint8Clamped version
		        if (size == 1 && len == 4) {
		            // Works as is
		            return new Uint8ClampedArray(buffer);
		        }

		        // Either the format, or type or both needs to be converted.
		        // Allocate a new buffer for the image
		        var lineCount = 4 * w;
		        var pixels = lineCount * h, i, j, k, endLine;
		        var padding = len * w * size;
		        padding = ((padding + align - 1) & ~(align - 1)) / size;
		        padding -= len * w;

		        function copyWithPadding(min, max) {
		            // Component fill R, then G, then B. Missing components
		            // in the source are set to 0, except for alpha which is set to 1.
		            var retBuf = new Uint8ClampedArray(pixels);
		            for (var i = 0, j = 0; i < pixels; j += padding) {
		                var endLine = i + lineCount;
		                for ( ; i < endLine; i += 4, j += len) {
		                    var k;
		                    for (k = 0; k < len; ++k) {
		                        retBuf[i + k] = (buffer[j + k] - min[k]) * max[k];
		                    }
		                    for (; k < 3; ++k) {
		                        retBuf[i + k] = 0;
		                    }
		                    for (; k < 4; ++k) {
		                        retBuf[i + k] = 255;
		                    }
		                }
		            }
		            return retBuf;
		        }

		        // If size == 1, then we just need to adjust the format.
		        if (size == 1) {
		            return copyWithPadding([0, 0, 0, 0], [1, 1, 1, 1]);
		        } else if (size != 4 && type != THREE.HalfFloatType) {
		            // Only support float, half-float or unsigned byte
		            zvp.logger.error("getRenderTargetPixels: Only byte and float types are supported");
		            return null;
		        }

		        // We have a float or half-float buffer.
		        var srcLen = (len * w + padding) * h;
		        if (size == 2) {
		            // Convert half floats to floats
		            var floatBuffer = new Float32Array(srcLen);
		            for (i = srcLen; (i -= padding) >= 0; ) {
		                endLine = i - len * w;
		                for ( ; --i >= endLine; ) {
		                    floatBuffer[i] = zvp.HalfToFloat(buffer[i]);
		                }
		            }
		            buffer = floatBuffer;
		        }

		        // We need to put floating point values into [0,1] range.
		        // We find the max and min values and map the range [floor(min), ceil(max)]
		        // to [0-1]. We ignore transparent pixels unless all of the
		        // pixels are transparent.
		        var maxVis = [-Infinity, -Infinity, -Infinity, -Infinity];
		        var minVis = [Infinity, Infinity, Infinity, Infinity];
		        var max = [-Infinity, -Infinity, -Infinity, -Infinity];
		        var min = [Infinity, Infinity, Infinity, Infinity];
		        // Find the max, min and max visible and min visible values
		        for (i = 0; i < srcLen; i += padding) {
		            endLine = i + len  * w;
		            for ( ; i < endLine; i += len) {
		                var visible = (len == 4) && (buffer[i + 3] != 0);
		                for (k = 0; k < len; ++k) {
		                    var val = buffer[i + k];
		                    if (val > max[k]) {
		                        max[k] = val;
		                    } else if (val < min[k]) {
		                        min[k] = val;
		                    }
		                    // Don't include transparent values in minVis and maxVis
		                    if (visible) {
		                        if (val > maxVis[k]) {
		                            maxVis[k] = val;
		                        } else if (val < minVis[k]) {
		                            minVis[k] = val;
		                        }
		                    }
		                }
		            }
		        }

		        if (isFinite(maxVis[0]) && min[3] >= 0 && max[3] <= 1) {
		            // We got visible pixels and alpha is in the range 0 to 1.
		            // Use the visible min and max rather than the global.
		            max = maxVis;
		            min = minVis;
		        } else {
		            // No visible pixels force alpha to 1
		            min[3] = -1;
		            max[3] = 0;
		        }
		        // Adjust the min and max to scale each component into [0,255]. When we are
		        // done we will scale the component value like this c = (c - min) * max.
		        for (k = 0; k < len; ++k) {
		            // Floor the min and ceil the max.
		            min[k] = Math.floor(min[k]);
		            max[k] = Math.ceil(max[k]) - min[k];
		            if (max[k] == 0) {
		                // Buffer has only a single integer value in it.
		                if (min[k] >= 0 && min[k] <= 1) {
		                    // Single value is between 0 and 1, so just use it
		                    min[k] = 0;
		                    max[k] = 1;
		                } else {
		                    // Outside of the range make it .5
		                    min[k] -= 0.5;
		                    max[k] = 1;
		                }
		            }
		            // Adjust [0-1] to [0-255]
		            max[k] = 255.0 / max[k];
		        }

		        // Now map the components.
		        return copyWithPadding(min, max);
		    }

		    var target = this.getNamedTarget(targetName);

		    if (!target) {
		        console.error('unknown target name');
		    } else {
		        var buffer = _renderer.readRenderTargetPixels(target, 0, 0, target.width, target.height);
		        if (buffer) {
		            buffer = convertBuffer(target.width, target.height, buffer);
		            var imgdata = new ImageData(buffer, target.width, target.height);
		            var canvas = document.createElement('canvas');
		            canvas.width = target.width;
		            canvas.height = target.height;
		            var context = canvas.getContext('2d');
		            context.putImageData(imgdata, 0, 0);
		            var newBlobURL = window.URL.createObjectURL(dataURLToBlob(canvas.toDataURL("image/png")));
		            window.open(newBlobURL);
		        }
		    }
		};
		*/

		/**
		 * {Number} vpx - OpenGL style X-coordinate [-1..1]
		 * {Number} vpy - OpenGL style Y-coordinate [-1..1]
		 */
		this.rolloverObjectViewport = function(vpx, vpy) {
			if(!_enableRolloverHighlight)
				return false;

			_idRes[1] = 0; // Reset model-id to 0
			var objId = this.idAtPixel(vpx, vpy, _idRes);
			return this.rolloverObjectId(objId, null, _idRes[1]);
		};

		/**
		 * {Number} objId - Main Integer id to highlight. If it's not a leaf node, 
		 *                  then the dbIds (presumable all its children) will also be highlighed, too.
		 * {Number} [dbIds] - OPTIONAL, id range to highlight.
		 * {Number} [modelId] - OPTIONAL, id of the model containing the id range.
		 */
		this.rolloverObjectId = function(objId, dbIds, modelId) {

			modelId = modelId || 0;

			//Check if nothing was at that pixel -- 0 means object
			//that has no ID, ffffff (-1) means background, and both result
			//in no highlight.
			if(objId <= 0) {
				objId = 0;
			}

			if(!_enableRolloverHighlight || (objId === _lastHighlightId && modelId === _lastHighlightModelId))
				return false;

			_blendPass.uniforms['highlightIntensity'].value = 0;
			_blendPass.uniforms['objID'].value = objId;

			_lastObjTime = performance.now();

			_lastHighlightId = objId;
			_lastHighlightModelId = modelId;

			// When dbIds is provided, highlight nodes in a range
			if(dbIds) {

				if(dbIds.length > 1)
					dbIds.shift();
				_blendPass.uniforms['highlightRange'].value = 1;
				_blendPass.uniforms['objIDStart'].value = dbIds[0];
				_blendPass.uniforms['objIDEnd'].value = dbIds[dbIds.length - 1];
			} else {

				_blendPass.uniforms['highlightRange'].value = 0;

				_blendPass.uniforms['objIDv4'].value.set((objId & 0xFF) / 255,
					((objId >> 8) & 0xFF) / 255,
					((objId >> 16) & 0xFF) / 255,
					((objId >> 24) & 0xFF) / 255
				);

				_blendPass.uniforms['modelIDv2'].value.set((modelId & 0xFF) / 255,
					((modelId >> 8) & 0xFF) / 255);
			}

			return true;
		};

		this.setSelectionColor = function(color) {
			// The selection color is gamma corrected using 2.0.
			var gamma = new THREE.Color(color);
			gamma.r = Math.pow(gamma.r, 2.0);
			gamma.g = Math.pow(gamma.g, 2.0);
			gamma.b = Math.pow(gamma.b, 2.0);
			_blendPass.uniforms['selectionColor'].value.set(gamma);
			_blendPass.material.needsUpdate = true;
		};

		this.setSelectionMaterials = function(materials) {
			_selectionMaterials.length = materials.length;
			for(var i = 0; i < materials.length; i++) {
				_selectionMaterials[i] = materials[i];
			}
			updateHighlightTargets();
			return true;
		};

		this.setMemoryLimited = function(memoryLimited) {
			_enableRolloverHighlight = !memoryLimited;
			_settings.idbuffer = _settings.idbuffer && _enableRolloverHighlight;
			_settings.occlusionid = memoryLimited;
			this.setSize(_w, _h); // Create/dispose idTargets if needed
		};

		this.isMemoryLimited = function() {
			return !_enableRolloverHighlight;
		};

		this.setUnitScale = function(metersPerUnit) {
			_unitScale = metersPerUnit;
		};

		this.getUnitScale = function() {
			return _unitScale;
		};

		this.getBlendPass = function() {
			return _blendPass;
		};

		this.getClearPass = function() {
			return _clearPass;
		};

		// TODO_NOP: hack expose colorTarget so shadow/reflection can draw into
		this.getColorTarget = function() {
			return _colorTarget;
		};

		/**
		 * @returns {WebGLRenderTarget} Normal/depth target for this context (if rendered)
		 */
		this.getDepthTarget = function() {
			return _depthTarget;
		};

		/**
		 * @returns {WebGLRenderTarget} Model ID target for this context (if rendered)
		 */
		this.getIdTarget = function() {
			return _idTargets[0];
		};

		// TODO_NOP: hack expose depthMaterial to register with matman for cutplanes
		this.getDepthMaterial = function() {
			return _depthMaterial;
		};

		this.getPostTarget = function() {
			return _postTarget1;
		};

		//TODO: Why not, adding another NOP-style hack
		this.getEdgeMaterial = function() {
			return _edgeMaterial;
		};

		this.getNamedTarget = function(targetName) {
			switch(targetName) {
				case 'color':
					return _colorTarget;
				case 'overlay':
					return _overlayTarget;
				case 'id':
					return _idTargets[0];
				case 'post1':
					return _postTarget1;
				case 'post2':
					return _postTarget2;
				case 'postdisplay':
					return _postProcDisplayTarget;
				case 'ssao':
					return _ssaoTarget;
				case 'occlusion':
					return _occlusionTarget;
				case 'depth':
					return _depthTarget;
				case 'highlight0':
					return _highlightTargets[0];
				case 'highlight1':
					return _highlightTargets[1];
				case 'highlight2':
					return _highlightTargets[2];
				case 'highlight3':
					return _highlightTargets[3];
			}
			return null;
		};

		/**
		 * @returns {WebGLFramebuffer} Currently bound framebuffer for this context
		 */
		this.getCurrentFramebuffer = function() {
			return _renderer.getCurrentFramebuffer();
		};
	}

	zvp.RenderContext = RenderContext;

})();;